{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"GRU_one_year_emergency.ipynb","provenance":[{"file_id":"1oRRafADxyOau4EipyBaHpt2p5hUJRlL2","timestamp":1599564147384},{"file_id":"1TrzaWHuaQdOSbarqKyNh2pVEIpdBbI2V","timestamp":1595873490211},{"file_id":"1n-bpqjs9N3twb2-j05nypXfhoIAIxLxw","timestamp":1593523257954},{"file_id":"1ltx24yUn21sW5x5CFpONkulkG0kD64Ok","timestamp":1588233646914}],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"BbQc45ZVFq7e","colab_type":"text"},"source":["# GRU neural network for EMS demand predictions\n","This notebook contains the code for applying neural network models to smart city data <br>\n"]},{"cell_type":"code","metadata":{"id":"sjXJ7KuSG2Em","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1599643411969,"user_tz":-120,"elapsed":8465,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"df0eca9e-9e3c-4d55-a1d9-876f4cbf1172"},"source":["# GPU check:\n","\n","import tensorflow as tf\n","tf.test.gpu_device_name()\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/device:GPU:0'"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"rSKD3TJEKZsG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":555},"executionInfo":{"status":"ok","timestamp":1599643411973,"user_tz":-120,"elapsed":6895,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"73d7559e-36e0-49b0-cd6d-0a4e6fc7a36f"},"source":["from tensorflow.python.client import device_lib\n","print(\"Show System RAM Memory: \\n \\n\")\n","!cat /proc/meminfo | egrep \"MemTotal\"\n","device_lib.list_local_devices()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Show System RAM Memory: \n"," \n","\n","MemTotal:       26751688 kB\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[name: \"/device:CPU:0\"\n"," device_type: \"CPU\"\n"," memory_limit: 268435456\n"," locality {\n"," }\n"," incarnation: 559503576835004651, name: \"/device:XLA_CPU:0\"\n"," device_type: \"XLA_CPU\"\n"," memory_limit: 17179869184\n"," locality {\n"," }\n"," incarnation: 3420919100551386495\n"," physical_device_desc: \"device: XLA_CPU device\", name: \"/device:XLA_GPU:0\"\n"," device_type: \"XLA_GPU\"\n"," memory_limit: 17179869184\n"," locality {\n"," }\n"," incarnation: 7183241010192726250\n"," physical_device_desc: \"device: XLA_GPU device\", name: \"/device:GPU:0\"\n"," device_type: \"GPU\"\n"," memory_limit: 15473775744\n"," locality {\n","   bus_id: 1\n","   links {\n","   }\n"," }\n"," incarnation: 7109277902584850429\n"," physical_device_desc: \"device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0\"]"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"eYoiZfKEqt6K","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1599643413754,"user_tz":-120,"elapsed":1286,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"2f1a141d-c214-4b25-95f0-81e27763bbd0"},"source":["# get additional info about the hardware in the cloud\n","%cat /proc/cpuinfo\n","%cat /proc/meminfo"],"execution_count":null,"outputs":[{"output_type":"stream","text":["processor\t: 0\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 79\n","model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2200.000\n","cache size\t: 56320 KB\n","physical id\t: 0\n","siblings\t: 4\n","core id\t\t: 0\n","cpu cores\t: 2\n","apicid\t\t: 0\n","initial apicid\t: 0\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa\n","bogomips\t: 4400.00\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 1\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 79\n","model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2200.000\n","cache size\t: 56320 KB\n","physical id\t: 0\n","siblings\t: 4\n","core id\t\t: 1\n","cpu cores\t: 2\n","apicid\t\t: 2\n","initial apicid\t: 2\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa\n","bogomips\t: 4400.00\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 2\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 79\n","model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2200.000\n","cache size\t: 56320 KB\n","physical id\t: 0\n","siblings\t: 4\n","core id\t\t: 0\n","cpu cores\t: 2\n","apicid\t\t: 1\n","initial apicid\t: 1\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa\n","bogomips\t: 4400.00\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 3\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 79\n","model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2200.000\n","cache size\t: 56320 KB\n","physical id\t: 0\n","siblings\t: 4\n","core id\t\t: 1\n","cpu cores\t: 2\n","apicid\t\t: 3\n","initial apicid\t: 3\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa\n","bogomips\t: 4400.00\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","MemTotal:       26751688 kB\n","MemFree:        22866184 kB\n","MemAvailable:   25226412 kB\n","Buffers:           96732 kB\n","Cached:          2363796 kB\n","SwapCached:            0 kB\n","Active:          1168484 kB\n","Inactive:        2268292 kB\n","Active(anon):     812024 kB\n","Inactive(anon):     8596 kB\n","Active(file):     356460 kB\n","Inactive(file):  2259696 kB\n","Unevictable:           0 kB\n","Mlocked:               0 kB\n","SwapTotal:             0 kB\n","SwapFree:              0 kB\n","Dirty:               740 kB\n","Writeback:             0 kB\n","AnonPages:        975972 kB\n","Mapped:           512292 kB\n","Shmem:              9164 kB\n","Slab:             197624 kB\n","SReclaimable:     133816 kB\n","SUnreclaim:        63808 kB\n","KernelStack:        4448 kB\n","PageTables:         8176 kB\n","NFS_Unstable:          0 kB\n","Bounce:                0 kB\n","WritebackTmp:          0 kB\n","CommitLimit:    13375844 kB\n","Committed_AS:    3409400 kB\n","VmallocTotal:   34359738367 kB\n","VmallocUsed:           0 kB\n","VmallocChunk:          0 kB\n","Percpu:             1904 kB\n","AnonHugePages:         0 kB\n","ShmemHugePages:        0 kB\n","ShmemPmdMapped:        0 kB\n","HugePages_Total:       0\n","HugePages_Free:        0\n","HugePages_Rsvd:        0\n","HugePages_Surp:        0\n","Hugepagesize:       2048 kB\n","Hugetlb:               0 kB\n","DirectMap4k:      181436 kB\n","DirectMap2M:     7157760 kB\n","DirectMap1G:    22020096 kB\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EGW0I0e2JPRF","colab_type":"text"},"source":["Tutorial about google colab and GPU access: <br>\n","https://www.youtube.com/watch?v=f1UK8KPt-KU"]},{"cell_type":"code","metadata":{"id":"qwj11IXMH72n","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":124},"executionInfo":{"status":"ok","timestamp":1599643456559,"user_tz":-120,"elapsed":39827,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"806d84fa-b38f-4ab3-b7cb-1ed51698556c"},"source":["# this allows for accessing files stored in your google drive using the path \"/gdrive/My Drive/\"\n","# mounting google drive locally:\n","\n","from google.colab import drive\n","drive.mount('/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","4/4AHiM91JRR2t5i8dvaTEN7UfwchOwsLcYrLz_VE2ftYhfh-nGOg6W4Y\n","Mounted at /gdrive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"YU95ui8cFq7l","colab_type":"text"},"source":["$\\textbf{Background:}$ Tensors are data structures that you can think of as multi-dimensional arrays. Tensors are represented as n-dimensional arrays of base dataypes such as a string or integer -- they provide a way to generalize vectors and matrices to higher dimensions. The shape of a Tensor defines its number of dimensions and the size of each dimension. The rank of a Tensor provides the number of dimensions. Scalars can be used to create 0-d Tensors. Vectors and lists can be used to create 1-d Tensors. Matrices can be used to create 2-d or higher rank Tensors. The shape of a Tensor provides the number of elements in each Tensor dimension."]},{"cell_type":"markdown","metadata":{"id":"E2keIBaUFq7o","colab_type":"text"},"source":["$\\textbf{Neural Networks in Tensorflow:}$ We can also define neural networks in TensorFlow. TensorFlow uses a high-level API called Keras that provides a powerful, intuitive framework for building and training deep learning models. <br> \n","Tensors can flow through abstract types called $\\textit{Layers}$ -- the building blocks of neural networks. Layers implement common neural networks operations, and are used to update weights, compute losses, and define inter-layer connectivity <br>\n","<br>\n","Conveniently, TensorFlow has defined a number of Layers that are commonly used in neural networks, for example a Dense. Now, instead of using a single Layer to define our simple neural network, we'll use the Sequential model from Keras and a single Dense layer to define our network. With the Sequential API, you can readily create neural networks by stacking together layers like building blocks."]},{"cell_type":"markdown","metadata":{"id":"OqXHoss3Fq7r","colab_type":"text"},"source":["# Implementation"]},{"cell_type":"code","metadata":{"id":"q-aQ4vhvFq7u","colab_type":"code","colab":{}},"source":["## -- Packages  -- ##\n","\n","# General\n","import pandas as pd\n","import numpy as np\n","\n","# Time formatting\n","import datetime\n","\n","# Load and save data\n","import pickle\n","# progress bar\n","from tqdm import tqdm\n","\n","# Plotting\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","#import tikzplotlib as tkz"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DAeGJ2aEFq7-","colab_type":"code","colab":{}},"source":["##  NN libaries ##\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","import tensorflow.keras.backend as K\n","\n","from sklearn.metrics import mean_squared_error\n","from sklearn.metrics import mean_absolute_error\n","from math import sqrt\n","\n","\n","## ML libraries ##\n","from keras.wrappers.scikit_learn import KerasRegressor\n","\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.model_selection import TimeSeriesSplit\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.model_selection import cross_val_score\n","\n","from sklearn.preprocessing import MinMaxScaler"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QWsyGxrfFq8L","colab_type":"text"},"source":["### Load data"]},{"cell_type":"code","metadata":{"id":"YsedO7PfFq8O","colab_type":"code","colab":{}},"source":["#load taxi data. Generated in notebook 'taxi_trips'\n","filename = '/gdrive/My Drive/Colab Notebooks/emergency_dispatches_bronx_H'\n","infile = open(filename,'rb')\n","emergency_ts = pickle.load(infile)\n","infile.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"pHvez5GsFq8X","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1599643466459,"user_tz":-120,"elapsed":1178,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"6e3a2086-9b00-45c2-9f6e-c53c00e157ab"},"source":["emergency_ts.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(8760,)"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"wc-6qP1mFq8i","colab_type":"text"},"source":["### Preprocessing"]},{"cell_type":"code","metadata":{"id":"yK6ejFwNbnYb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1599643466818,"user_tz":-120,"elapsed":794,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"4488deaa-e3d3-4901-9058-c9908bcb5624"},"source":["## Remove last 15 days of data since they are either erroneous or part of the test set to the robustness checks\n","emergency_ts_final = emergency_ts.iloc[0:-360]\n","emergency_ts_final.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(8400,)"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"-gTDE4GqFq8k","colab_type":"code","colab":{}},"source":["## Set paramaters\n","input_lags = 60 # 2 and a half times the seasonal period\n","output_lags = 24 # we predict 24 hours ahead\n","n_test = 24 # output_lags  (changed)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iyMAi8oaFq8t","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1599643469863,"user_tz":-120,"elapsed":422,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"b33e5d09-d2ae-45fb-dacd-85c35c996c31"},"source":["## Split data in train and test set\n","train = emergency_ts_final[0:-n_test]\n","test = emergency_ts_final[-n_test:]\n","print(train.shape)\n","print(test.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(8376,)\n","(24,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"E17SmtS0Fq81","colab_type":"code","colab":{}},"source":["## Create lagged values for both input and output window (24)\n","data = train.copy()\n","n_train = len(data)\n","\n","##Create lagged values for input\n","df = pd.DataFrame()\n","for i in range(input_lags,0,-1):\n","    df['t-' + str(i)] = data.shift(i)\n","\n","##Create lagged values for output\n","for j in range(0,output_lags,1):\n","    df['t+' + str(j)] = data.shift(-j)\n","    \n","df = df[input_lags:(n_train-output_lags+1)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r2WaRRmoFq87","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":287},"executionInfo":{"status":"ok","timestamp":1599643475766,"user_tz":-120,"elapsed":1230,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"133cbcfa-f613-4b7b-ecf5-d624a33952ab"},"source":["df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>t-60</th>\n","      <th>t-59</th>\n","      <th>t-58</th>\n","      <th>t-57</th>\n","      <th>t-56</th>\n","      <th>t-55</th>\n","      <th>t-54</th>\n","      <th>t-53</th>\n","      <th>t-52</th>\n","      <th>t-51</th>\n","      <th>t-50</th>\n","      <th>t-49</th>\n","      <th>t-48</th>\n","      <th>t-47</th>\n","      <th>t-46</th>\n","      <th>t-45</th>\n","      <th>t-44</th>\n","      <th>t-43</th>\n","      <th>t-42</th>\n","      <th>t-41</th>\n","      <th>t-40</th>\n","      <th>t-39</th>\n","      <th>t-38</th>\n","      <th>t-37</th>\n","      <th>t-36</th>\n","      <th>t-35</th>\n","      <th>t-34</th>\n","      <th>t-33</th>\n","      <th>t-32</th>\n","      <th>t-31</th>\n","      <th>t-30</th>\n","      <th>t-29</th>\n","      <th>t-28</th>\n","      <th>t-27</th>\n","      <th>t-26</th>\n","      <th>t-25</th>\n","      <th>t-24</th>\n","      <th>t-23</th>\n","      <th>t-22</th>\n","      <th>t-21</th>\n","      <th>...</th>\n","      <th>t-16</th>\n","      <th>t-15</th>\n","      <th>t-14</th>\n","      <th>t-13</th>\n","      <th>t-12</th>\n","      <th>t-11</th>\n","      <th>t-10</th>\n","      <th>t-9</th>\n","      <th>t-8</th>\n","      <th>t-7</th>\n","      <th>t-6</th>\n","      <th>t-5</th>\n","      <th>t-4</th>\n","      <th>t-3</th>\n","      <th>t-2</th>\n","      <th>t-1</th>\n","      <th>t+0</th>\n","      <th>t+1</th>\n","      <th>t+2</th>\n","      <th>t+3</th>\n","      <th>t+4</th>\n","      <th>t+5</th>\n","      <th>t+6</th>\n","      <th>t+7</th>\n","      <th>t+8</th>\n","      <th>t+9</th>\n","      <th>t+10</th>\n","      <th>t+11</th>\n","      <th>t+12</th>\n","      <th>t+13</th>\n","      <th>t+14</th>\n","      <th>t+15</th>\n","      <th>t+16</th>\n","      <th>t+17</th>\n","      <th>t+18</th>\n","      <th>t+19</th>\n","      <th>t+20</th>\n","      <th>t+21</th>\n","      <th>t+22</th>\n","      <th>t+23</th>\n","    </tr>\n","    <tr>\n","      <th>FIRST_ASSIGNMENT_DATETIME</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2019-01-03 12:00:00</th>\n","      <td>41.0</td>\n","      <td>48.0</td>\n","      <td>36.0</td>\n","      <td>55.0</td>\n","      <td>48.0</td>\n","      <td>27.0</td>\n","      <td>47.0</td>\n","      <td>46.0</td>\n","      <td>58.0</td>\n","      <td>51.0</td>\n","      <td>42.0</td>\n","      <td>50.0</td>\n","      <td>62.0</td>\n","      <td>44.0</td>\n","      <td>47.0</td>\n","      <td>58.0</td>\n","      <td>44.0</td>\n","      <td>53.0</td>\n","      <td>44.0</td>\n","      <td>43.0</td>\n","      <td>44.0</td>\n","      <td>38.0</td>\n","      <td>45.0</td>\n","      <td>35.0</td>\n","      <td>34.0</td>\n","      <td>38.0</td>\n","      <td>26.0</td>\n","      <td>23.0</td>\n","      <td>17.0</td>\n","      <td>21.0</td>\n","      <td>27.0</td>\n","      <td>39.0</td>\n","      <td>37.0</td>\n","      <td>53.0</td>\n","      <td>67.0</td>\n","      <td>50.0</td>\n","      <td>69.0</td>\n","      <td>59.0</td>\n","      <td>66.0</td>\n","      <td>50.0</td>\n","      <td>...</td>\n","      <td>60.0</td>\n","      <td>45.0</td>\n","      <td>41.0</td>\n","      <td>34.0</td>\n","      <td>36.0</td>\n","      <td>24.0</td>\n","      <td>19.0</td>\n","      <td>29.0</td>\n","      <td>21.0</td>\n","      <td>23.0</td>\n","      <td>31.0</td>\n","      <td>26.0</td>\n","      <td>42.0</td>\n","      <td>57.0</td>\n","      <td>63.0</td>\n","      <td>56.0</td>\n","      <td>65</td>\n","      <td>56.0</td>\n","      <td>47.0</td>\n","      <td>59.0</td>\n","      <td>58.0</td>\n","      <td>55.0</td>\n","      <td>48.0</td>\n","      <td>47.0</td>\n","      <td>44.0</td>\n","      <td>36.0</td>\n","      <td>37.0</td>\n","      <td>40.0</td>\n","      <td>39.0</td>\n","      <td>31.0</td>\n","      <td>22.0</td>\n","      <td>17.0</td>\n","      <td>13.0</td>\n","      <td>17.0</td>\n","      <td>31.0</td>\n","      <td>37.0</td>\n","      <td>46.0</td>\n","      <td>48.0</td>\n","      <td>38.0</td>\n","      <td>54.0</td>\n","    </tr>\n","    <tr>\n","      <th>2019-01-03 13:00:00</th>\n","      <td>48.0</td>\n","      <td>36.0</td>\n","      <td>55.0</td>\n","      <td>48.0</td>\n","      <td>27.0</td>\n","      <td>47.0</td>\n","      <td>46.0</td>\n","      <td>58.0</td>\n","      <td>51.0</td>\n","      <td>42.0</td>\n","      <td>50.0</td>\n","      <td>62.0</td>\n","      <td>44.0</td>\n","      <td>47.0</td>\n","      <td>58.0</td>\n","      <td>44.0</td>\n","      <td>53.0</td>\n","      <td>44.0</td>\n","      <td>43.0</td>\n","      <td>44.0</td>\n","      <td>38.0</td>\n","      <td>45.0</td>\n","      <td>35.0</td>\n","      <td>34.0</td>\n","      <td>38.0</td>\n","      <td>26.0</td>\n","      <td>23.0</td>\n","      <td>17.0</td>\n","      <td>21.0</td>\n","      <td>27.0</td>\n","      <td>39.0</td>\n","      <td>37.0</td>\n","      <td>53.0</td>\n","      <td>67.0</td>\n","      <td>50.0</td>\n","      <td>69.0</td>\n","      <td>59.0</td>\n","      <td>66.0</td>\n","      <td>50.0</td>\n","      <td>70.0</td>\n","      <td>...</td>\n","      <td>45.0</td>\n","      <td>41.0</td>\n","      <td>34.0</td>\n","      <td>36.0</td>\n","      <td>24.0</td>\n","      <td>19.0</td>\n","      <td>29.0</td>\n","      <td>21.0</td>\n","      <td>23.0</td>\n","      <td>31.0</td>\n","      <td>26.0</td>\n","      <td>42.0</td>\n","      <td>57.0</td>\n","      <td>63.0</td>\n","      <td>56.0</td>\n","      <td>65.0</td>\n","      <td>56</td>\n","      <td>47.0</td>\n","      <td>59.0</td>\n","      <td>58.0</td>\n","      <td>55.0</td>\n","      <td>48.0</td>\n","      <td>47.0</td>\n","      <td>44.0</td>\n","      <td>36.0</td>\n","      <td>37.0</td>\n","      <td>40.0</td>\n","      <td>39.0</td>\n","      <td>31.0</td>\n","      <td>22.0</td>\n","      <td>17.0</td>\n","      <td>13.0</td>\n","      <td>17.0</td>\n","      <td>31.0</td>\n","      <td>37.0</td>\n","      <td>46.0</td>\n","      <td>48.0</td>\n","      <td>38.0</td>\n","      <td>54.0</td>\n","      <td>68.0</td>\n","    </tr>\n","    <tr>\n","      <th>2019-01-03 14:00:00</th>\n","      <td>36.0</td>\n","      <td>55.0</td>\n","      <td>48.0</td>\n","      <td>27.0</td>\n","      <td>47.0</td>\n","      <td>46.0</td>\n","      <td>58.0</td>\n","      <td>51.0</td>\n","      <td>42.0</td>\n","      <td>50.0</td>\n","      <td>62.0</td>\n","      <td>44.0</td>\n","      <td>47.0</td>\n","      <td>58.0</td>\n","      <td>44.0</td>\n","      <td>53.0</td>\n","      <td>44.0</td>\n","      <td>43.0</td>\n","      <td>44.0</td>\n","      <td>38.0</td>\n","      <td>45.0</td>\n","      <td>35.0</td>\n","      <td>34.0</td>\n","      <td>38.0</td>\n","      <td>26.0</td>\n","      <td>23.0</td>\n","      <td>17.0</td>\n","      <td>21.0</td>\n","      <td>27.0</td>\n","      <td>39.0</td>\n","      <td>37.0</td>\n","      <td>53.0</td>\n","      <td>67.0</td>\n","      <td>50.0</td>\n","      <td>69.0</td>\n","      <td>59.0</td>\n","      <td>66.0</td>\n","      <td>50.0</td>\n","      <td>70.0</td>\n","      <td>51.0</td>\n","      <td>...</td>\n","      <td>41.0</td>\n","      <td>34.0</td>\n","      <td>36.0</td>\n","      <td>24.0</td>\n","      <td>19.0</td>\n","      <td>29.0</td>\n","      <td>21.0</td>\n","      <td>23.0</td>\n","      <td>31.0</td>\n","      <td>26.0</td>\n","      <td>42.0</td>\n","      <td>57.0</td>\n","      <td>63.0</td>\n","      <td>56.0</td>\n","      <td>65.0</td>\n","      <td>56.0</td>\n","      <td>47</td>\n","      <td>59.0</td>\n","      <td>58.0</td>\n","      <td>55.0</td>\n","      <td>48.0</td>\n","      <td>47.0</td>\n","      <td>44.0</td>\n","      <td>36.0</td>\n","      <td>37.0</td>\n","      <td>40.0</td>\n","      <td>39.0</td>\n","      <td>31.0</td>\n","      <td>22.0</td>\n","      <td>17.0</td>\n","      <td>13.0</td>\n","      <td>17.0</td>\n","      <td>31.0</td>\n","      <td>37.0</td>\n","      <td>46.0</td>\n","      <td>48.0</td>\n","      <td>38.0</td>\n","      <td>54.0</td>\n","      <td>68.0</td>\n","      <td>51.0</td>\n","    </tr>\n","    <tr>\n","      <th>2019-01-03 15:00:00</th>\n","      <td>55.0</td>\n","      <td>48.0</td>\n","      <td>27.0</td>\n","      <td>47.0</td>\n","      <td>46.0</td>\n","      <td>58.0</td>\n","      <td>51.0</td>\n","      <td>42.0</td>\n","      <td>50.0</td>\n","      <td>62.0</td>\n","      <td>44.0</td>\n","      <td>47.0</td>\n","      <td>58.0</td>\n","      <td>44.0</td>\n","      <td>53.0</td>\n","      <td>44.0</td>\n","      <td>43.0</td>\n","      <td>44.0</td>\n","      <td>38.0</td>\n","      <td>45.0</td>\n","      <td>35.0</td>\n","      <td>34.0</td>\n","      <td>38.0</td>\n","      <td>26.0</td>\n","      <td>23.0</td>\n","      <td>17.0</td>\n","      <td>21.0</td>\n","      <td>27.0</td>\n","      <td>39.0</td>\n","      <td>37.0</td>\n","      <td>53.0</td>\n","      <td>67.0</td>\n","      <td>50.0</td>\n","      <td>69.0</td>\n","      <td>59.0</td>\n","      <td>66.0</td>\n","      <td>50.0</td>\n","      <td>70.0</td>\n","      <td>51.0</td>\n","      <td>55.0</td>\n","      <td>...</td>\n","      <td>34.0</td>\n","      <td>36.0</td>\n","      <td>24.0</td>\n","      <td>19.0</td>\n","      <td>29.0</td>\n","      <td>21.0</td>\n","      <td>23.0</td>\n","      <td>31.0</td>\n","      <td>26.0</td>\n","      <td>42.0</td>\n","      <td>57.0</td>\n","      <td>63.0</td>\n","      <td>56.0</td>\n","      <td>65.0</td>\n","      <td>56.0</td>\n","      <td>47.0</td>\n","      <td>59</td>\n","      <td>58.0</td>\n","      <td>55.0</td>\n","      <td>48.0</td>\n","      <td>47.0</td>\n","      <td>44.0</td>\n","      <td>36.0</td>\n","      <td>37.0</td>\n","      <td>40.0</td>\n","      <td>39.0</td>\n","      <td>31.0</td>\n","      <td>22.0</td>\n","      <td>17.0</td>\n","      <td>13.0</td>\n","      <td>17.0</td>\n","      <td>31.0</td>\n","      <td>37.0</td>\n","      <td>46.0</td>\n","      <td>48.0</td>\n","      <td>38.0</td>\n","      <td>54.0</td>\n","      <td>68.0</td>\n","      <td>51.0</td>\n","      <td>55.0</td>\n","    </tr>\n","    <tr>\n","      <th>2019-01-03 16:00:00</th>\n","      <td>48.0</td>\n","      <td>27.0</td>\n","      <td>47.0</td>\n","      <td>46.0</td>\n","      <td>58.0</td>\n","      <td>51.0</td>\n","      <td>42.0</td>\n","      <td>50.0</td>\n","      <td>62.0</td>\n","      <td>44.0</td>\n","      <td>47.0</td>\n","      <td>58.0</td>\n","      <td>44.0</td>\n","      <td>53.0</td>\n","      <td>44.0</td>\n","      <td>43.0</td>\n","      <td>44.0</td>\n","      <td>38.0</td>\n","      <td>45.0</td>\n","      <td>35.0</td>\n","      <td>34.0</td>\n","      <td>38.0</td>\n","      <td>26.0</td>\n","      <td>23.0</td>\n","      <td>17.0</td>\n","      <td>21.0</td>\n","      <td>27.0</td>\n","      <td>39.0</td>\n","      <td>37.0</td>\n","      <td>53.0</td>\n","      <td>67.0</td>\n","      <td>50.0</td>\n","      <td>69.0</td>\n","      <td>59.0</td>\n","      <td>66.0</td>\n","      <td>50.0</td>\n","      <td>70.0</td>\n","      <td>51.0</td>\n","      <td>55.0</td>\n","      <td>53.0</td>\n","      <td>...</td>\n","      <td>36.0</td>\n","      <td>24.0</td>\n","      <td>19.0</td>\n","      <td>29.0</td>\n","      <td>21.0</td>\n","      <td>23.0</td>\n","      <td>31.0</td>\n","      <td>26.0</td>\n","      <td>42.0</td>\n","      <td>57.0</td>\n","      <td>63.0</td>\n","      <td>56.0</td>\n","      <td>65.0</td>\n","      <td>56.0</td>\n","      <td>47.0</td>\n","      <td>59.0</td>\n","      <td>58</td>\n","      <td>55.0</td>\n","      <td>48.0</td>\n","      <td>47.0</td>\n","      <td>44.0</td>\n","      <td>36.0</td>\n","      <td>37.0</td>\n","      <td>40.0</td>\n","      <td>39.0</td>\n","      <td>31.0</td>\n","      <td>22.0</td>\n","      <td>17.0</td>\n","      <td>13.0</td>\n","      <td>17.0</td>\n","      <td>31.0</td>\n","      <td>37.0</td>\n","      <td>46.0</td>\n","      <td>48.0</td>\n","      <td>38.0</td>\n","      <td>54.0</td>\n","      <td>68.0</td>\n","      <td>51.0</td>\n","      <td>55.0</td>\n","      <td>56.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows Ã— 84 columns</p>\n","</div>"],"text/plain":["                           t-60  t-59  t-58  t-57  ...  t+20  t+21  t+22  t+23\n","FIRST_ASSIGNMENT_DATETIME                          ...                        \n","2019-01-03 12:00:00        41.0  48.0  36.0  55.0  ...  46.0  48.0  38.0  54.0\n","2019-01-03 13:00:00        48.0  36.0  55.0  48.0  ...  48.0  38.0  54.0  68.0\n","2019-01-03 14:00:00        36.0  55.0  48.0  27.0  ...  38.0  54.0  68.0  51.0\n","2019-01-03 15:00:00        55.0  48.0  27.0  47.0  ...  54.0  68.0  51.0  55.0\n","2019-01-03 16:00:00        48.0  27.0  47.0  46.0  ...  68.0  51.0  55.0  56.0\n","\n","[5 rows x 84 columns]"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"w3kdgtGuFq9G","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":86},"executionInfo":{"status":"ok","timestamp":1599643476125,"user_tz":-120,"elapsed":425,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"1749aaef-03c0-42f7-b378-64fb452f894e"},"source":["## splitting the training set into labels and features\n","X_train = df.iloc[:,:input_lags] # from the beginning to input_lags\n","Y_train = df.iloc[:,input_lags:] # from input_lags to the end\n","\n","## Use the last window of the training set as the features for the test set. This requires a combination of \n","## X_train and Y_train.\n","X_test = X_train.iloc[len(X_train) - 1,:][output_lags:]\n","X_test = X_test.append(Y_train.iloc[len(Y_train) - 1,:]).values.reshape(1,input_lags)\n","Y_test = test[:output_lags].values.reshape(1,output_lags)\n","\n","X_train = X_train.values # 54 steps back (54 lags)\n","Y_train = Y_train.values # 24 steps ahead\n","\n","print(\"X_train: \" + \"type: \" + str(type(X_train)) + \"\\tshape: \" + str(X_train.shape))\n","print(\"Y_train: \" + \"type: \" + str(type(Y_train)) + \"\\tshape: \" + str(Y_train.shape))\n","print(\"X_test: \" + \"type: \" + str(type(X_test)) + \"\\tshape: \" + str(X_test.shape))\n","print(\"Y_test: \" + \"type: \" + str(type(Y_test)) + \"\\tshape: \" + str(Y_test.shape))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["X_train: type: <class 'numpy.ndarray'>\tshape: (8293, 60)\n","Y_train: type: <class 'numpy.ndarray'>\tshape: (8293, 24)\n","X_test: type: <class 'numpy.ndarray'>\tshape: (1, 60)\n","Y_test: type: <class 'numpy.ndarray'>\tshape: (1, 24)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6JtY4EfnFq9O","colab_type":"text"},"source":["$\\textbf{When Should You Use Normalization And Standardization:}$\n","\n","Normalization is a good technique to use when you do not know the distribution of your data or when you know the distribution is not Gaussian (a bell curve). Normalization is useful when your data has varying scales and the algorithm you are using does not make assumptions about the distribution of your data, such as k-nearest neighbors and artificial neural networks."]},{"cell_type":"code","metadata":{"id":"uKCNrdoFFq9P","colab_type":"code","colab":{}},"source":["## normalizing the data\n","\n","# MinMaxScaler() transforms features by scaling each feature to a given range (given by feature_range())\n","# The cost of having this bounded range is that we will end up with smaller standard deviations, which can \n","# suppress the effect of outliers. Thus MinMax Scalar is sensitive to outliers\n","\n","#scaler = MinMaxScaler(feature_range=(0, 1))\n","#df_x = df.iloc[:,0:24]\n","# the method fit_transform() computes the min and the max used for scaling and then carries out the transformation\n","#df_x_scaled = scaler.fit_transform(df_x)\n","# later, inverse_transform() can be used to undo the scaling to the feature_range\n","\n","# normalizing the entire dataset\n","#df_normalized = scaler.fit_transform(df)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CudYc-h8Fq-n","colab_type":"text"},"source":["# Building the GRU neural network model"]},{"cell_type":"markdown","metadata":{"id":"x3cox-4OFq-o","colab_type":"text"},"source":["# Method 1 (Keras)"]},{"cell_type":"markdown","metadata":{"id":"KunoTmoDFq-p","colab_type":"text"},"source":["Tensorflow 2.0 Impelementation <br>\n","(tf.keras is TensorFlow's implementation of the Keras API specification. This is a high-level API to build and train models that includes first-class support for TensorFlow-specific functionality)\n"]},{"cell_type":"markdown","metadata":{"id":"kP37YFrcFq-q","colab_type":"text"},"source":["TF 2 keras RNN tutorial\n","https://www.tensorflow.org/guide/keras/rnn <br>\n","TF 2 time series forecasting tutorial\n","https://www.tensorflow.org/tutorials/structured_data/time_series"]},{"cell_type":"code","metadata":{"id":"LFs50q62Fq-r","colab_type":"code","colab":{}},"source":["# configuring the inputs for the model\n","# For Keras, the input has to be in the shape (samples, time steps, features)\n","# 24 timestep with n features where n is equal to the shape of column [1] of X_train or X_test\n","\n","X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n","X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3PLMBsRNFq-z","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1599643492995,"user_tz":-120,"elapsed":1102,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"cf9504d9-736f-412a-f53a-98af9bdb99b2"},"source":["X_train.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(8293, 1, 60)"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"EINcqdSFFq-4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1599643493773,"user_tz":-120,"elapsed":1129,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"ec0bf23c-37bb-4fad-d2ac-03da65acc83f"},"source":["X_test.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1, 1, 60)"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"EXHvherGNfzW","colab_type":"code","colab":{}},"source":["# creating a leaky_relu activation function\n","\n","def my_leaky_relu(x):\n","    return tf.nn.leaky_relu(x)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F3e1wKsrFq_A","colab_type":"text"},"source":["## Gridsearch CV for the optimal hyperparameters"]},{"cell_type":"markdown","metadata":{"id":"WP2YyG5nFq_B","colab_type":"text"},"source":["Guide to Hyperparameter tuning: <br>\n","https://towardsdatascience.com/simple-guide-to-hyperparameter-tuning-in-neural-networks-3fe03dad8594\n","Dropout regularization for RNNs: <br>\n","https://machinelearningmastery.com/how-to-reduce-overfitting-with-dropout-regularization-in-keras/"]},{"cell_type":"markdown","metadata":{"id":"ivrkSlB8Fq_C","colab_type":"text"},"source":["\n","## One step Gridsearch CV for all hyperparameters"]},{"cell_type":"markdown","metadata":{"id":"ZmPTxaPtsQS-","colab_type":"text"},"source":["**Blogpost Hyperparametertuning LSTM/GRU:**\n","\n","https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/"]},{"cell_type":"markdown","metadata":{"id":"3CYwrepYtF-q","colab_type":"text"},"source":["**Overview of Gradient Descent Algorithms:**\n","\n","https://ruder.io/optimizing-gradient-descent/index.html#adagrad"]},{"cell_type":"code","metadata":{"id":"bhpKNYRsFq_D","colab_type":"code","colab":{}},"source":["# creating the parameter grid as a dictionary\n","\n","##\n","batch_size = [100, 200, 400]\n","epochs = [500, 1000, 1500]\n","neurons = [1000, 1500, 2000]\n","dropout = [0.0]\n","learning_rate = [0.01, 0.001, 0.0005]\n","optimizer = ['Adam']\n","\n","\n","param_grid_cv = dict(batch_size=batch_size, epochs=epochs, neurons=neurons, dropout = dropout, optimizer=optimizer, learning_rate = learning_rate)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ggWxYYddQ3g6","colab_type":"code","colab":{}},"source":["# refined grid\n","\n","batch_size = [150, 250]\n","epochs = [750, 1000]\n","neurons = [1500, 2000]\n","dropout = [0.0]\n","learning_rate = [0,01, 0.001, 0.0001]\n","optimizer = ['Adam', 'Adadelta']\n","\n","param_grid_cv = dict(batch_size=batch_size, epochs=epochs, neurons=neurons, dropout = dropout, optimizer=optimizer, learning_rate = learning_rate)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qu_O4-CjFq_I","colab_type":"code","colab":{}},"source":["# setting up the model\n","# the default activation function is tanh()\n","\n","def model(neurons = 128, epochs = 100, batch_size =100, dropout = 0.0, learning_rate = 0.001, optimizer=\"Adam\"):\n","    model = tf.keras.Sequential()\n","\n","# Add a GRU layer with 128 units (=dimensionality of the output space = number of neurons)\n","# option1: return sequences returns the hidden state output for each input time step.\n","# option2: return state returns the hidden state output and cell state for the last input time step.\n","# The output of GRU will be a 3D tensor of shape (batch_size, timesteps, 128)\n","    model.add(tf.keras.layers.GRU(units=neurons, return_sequences = False, input_shape = (1,60), dropout = dropout, activation = my_leaky_relu))\n","\n","# output layer with 24 neurons\n","    model.add(tf.keras.layers.Dense(24))\n","# the compile() method configures the model for training\n","    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate = learning_rate),\n","              loss=tf.keras.losses.mean_squared_error,\n","              metrics=['mean_squared_error'])\n","    \n","    return model\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I3PJbrwyFq_O","colab_type":"code","colab":{}},"source":["# using the KerasRegressor as a wrapper to carry out the GridSearchCV\n","model_cv = KerasRegressor(build_fn = model, verbose=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HYBVusgpFq_T","colab_type":"code","colab":{}},"source":["# k fold CV (NEW GRID for EMS data)\n","inner_splits = 3\n","inner_loop = TimeSeriesSplit(n_splits = inner_splits).split(X_train,Y_train)\n","\n","# n_jobs set to 4 means that 4 cores are used for parallel processing; set n_jobs=-1 to use all available cores\n","\n","grid_cv = GridSearchCV(estimator = model_cv, param_grid = param_grid_cv, cv = inner_loop, verbose = 3, n_jobs=-1)\n","grid_result = grid_cv.fit(X_train,Y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W4EHMGFOFq_-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":850},"executionInfo":{"status":"ok","timestamp":1599600022414,"user_tz":-120,"elapsed":552,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"6c77cacf-4eec-4fe8-e812-033679190889"},"source":["# summarize results\n","print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n","means = grid_result.cv_results_['mean_test_score']\n","stds = grid_result.cv_results_['std_test_score']\n","params = grid_result.cv_results_['params']\n","for mean, stdev, param in zip(means, stds, params):\n","    print(\"%f (%f) with: %r\" % (mean, stdev, param))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Best: -62.414964 using {'batch_size': 250, 'dropout': 0.0, 'epochs': 750, 'learning_rate': 0.01, 'neurons': 2000, 'optimizer': 'Adam'}\n","-92.200343 (29.365974) with: {'batch_size': 150, 'dropout': 0.0, 'epochs': 750, 'learning_rate': 0.01, 'neurons': 1500, 'optimizer': 'Adam'}\n","-161.357597 (86.164358) with: {'batch_size': 150, 'dropout': 0.0, 'epochs': 750, 'learning_rate': 0.01, 'neurons': 1500, 'optimizer': 'Adadelta'}\n","-245.919278 (238.326770) with: {'batch_size': 150, 'dropout': 0.0, 'epochs': 750, 'learning_rate': 0.01, 'neurons': 2000, 'optimizer': 'Adam'}\n","-286.490025 (206.873506) with: {'batch_size': 150, 'dropout': 0.0, 'epochs': 750, 'learning_rate': 0.01, 'neurons': 2000, 'optimizer': 'Adadelta'}\n","-75.131762 (8.137463) with: {'batch_size': 150, 'dropout': 0.0, 'epochs': 750, 'learning_rate': 0.001, 'neurons': 1500, 'optimizer': 'Adam'}\n","-76.444692 (7.812122) with: {'batch_size': 150, 'dropout': 0.0, 'epochs': 750, 'learning_rate': 0.001, 'neurons': 1500, 'optimizer': 'Adadelta'}\n","-76.979968 (9.042548) with: {'batch_size': 150, 'dropout': 0.0, 'epochs': 750, 'learning_rate': 0.001, 'neurons': 2000, 'optimizer': 'Adam'}\n","-78.506872 (8.006291) with: {'batch_size': 150, 'dropout': 0.0, 'epochs': 750, 'learning_rate': 0.001, 'neurons': 2000, 'optimizer': 'Adadelta'}\n","-73.826441 (7.689208) with: {'batch_size': 150, 'dropout': 0.0, 'epochs': 750, 'learning_rate': 0.0001, 'neurons': 1500, 'optimizer': 'Adam'}\n","-73.662720 (7.250188) with: {'batch_size': 150, 'dropout': 0.0, 'epochs': 750, 'learning_rate': 0.0001, 'neurons': 1500, 'optimizer': 'Adadelta'}\n","-75.863083 (7.225729) with: {'batch_size': 150, 'dropout': 0.0, 'epochs': 750, 'learning_rate': 0.0001, 'neurons': 2000, 'optimizer': 'Adam'}\n","-74.482635 (6.229200) with: {'batch_size': 150, 'dropout': 0.0, 'epochs': 750, 'learning_rate': 0.0001, 'neurons': 2000, 'optimizer': 'Adadelta'}\n","-74.087495 (16.860105) with: {'batch_size': 150, 'dropout': 0.0, 'epochs': 1000, 'learning_rate': 0.01, 'neurons': 1500, 'optimizer': 'Adam'}\n","-68.365542 (3.263079) with: {'batch_size': 150, 'dropout': 0.0, 'epochs': 1000, 'learning_rate': 0.01, 'neurons': 1500, 'optimizer': 'Adadelta'}\n","-125.643893 (23.076880) with: {'batch_size': 150, 'dropout': 0.0, 'epochs': 1000, 'learning_rate': 0.01, 'neurons': 2000, 'optimizer': 'Adam'}\n","-75.328618 (18.476525) with: {'batch_size': 150, 'dropout': 0.0, 'epochs': 1000, 'learning_rate': 0.01, 'neurons': 2000, 'optimizer': 'Adadelta'}\n","-81.429957 (9.970512) with: {'batch_size': 150, 'dropout': 0.0, 'epochs': 1000, 'learning_rate': 0.001, 'neurons': 1500, 'optimizer': 'Adam'}\n","-81.012113 (9.327684) with: {'batch_size': 150, 'dropout': 0.0, 'epochs': 1000, 'learning_rate': 0.001, 'neurons': 1500, 'optimizer': 'Adadelta'}\n","-82.995585 (9.533161) with: {'batch_size': 150, 'dropout': 0.0, 'epochs': 1000, 'learning_rate': 0.001, 'neurons': 2000, 'optimizer': 'Adam'}\n","-82.555616 (9.164885) with: {'batch_size': 150, 'dropout': 0.0, 'epochs': 1000, 'learning_rate': 0.001, 'neurons': 2000, 'optimizer': 'Adadelta'}\n","-81.590719 (8.695623) with: {'batch_size': 150, 'dropout': 0.0, 'epochs': 1000, 'learning_rate': 0.0001, 'neurons': 1500, 'optimizer': 'Adam'}\n","-80.823341 (7.310823) with: {'batch_size': 150, 'dropout': 0.0, 'epochs': 1000, 'learning_rate': 0.0001, 'neurons': 1500, 'optimizer': 'Adadelta'}\n","-82.332965 (6.941361) with: {'batch_size': 150, 'dropout': 0.0, 'epochs': 1000, 'learning_rate': 0.0001, 'neurons': 2000, 'optimizer': 'Adam'}\n","-82.195989 (7.777063) with: {'batch_size': 150, 'dropout': 0.0, 'epochs': 1000, 'learning_rate': 0.0001, 'neurons': 2000, 'optimizer': 'Adadelta'}\n","-77.002139 (12.729199) with: {'batch_size': 250, 'dropout': 0.0, 'epochs': 750, 'learning_rate': 0.01, 'neurons': 1500, 'optimizer': 'Adam'}\n","-72.733667 (11.982547) with: {'batch_size': 250, 'dropout': 0.0, 'epochs': 750, 'learning_rate': 0.01, 'neurons': 1500, 'optimizer': 'Adadelta'}\n","-62.414964 (3.402387) with: {'batch_size': 250, 'dropout': 0.0, 'epochs': 750, 'learning_rate': 0.01, 'neurons': 2000, 'optimizer': 'Adam'}\n","-161.587873 (120.574352) with: {'batch_size': 250, 'dropout': 0.0, 'epochs': 750, 'learning_rate': 0.01, 'neurons': 2000, 'optimizer': 'Adadelta'}\n","-71.789513 (7.085853) with: {'batch_size': 250, 'dropout': 0.0, 'epochs': 750, 'learning_rate': 0.001, 'neurons': 1500, 'optimizer': 'Adam'}\n","-72.165387 (7.280601) with: {'batch_size': 250, 'dropout': 0.0, 'epochs': 750, 'learning_rate': 0.001, 'neurons': 1500, 'optimizer': 'Adadelta'}\n","-73.518092 (7.158583) with: {'batch_size': 250, 'dropout': 0.0, 'epochs': 750, 'learning_rate': 0.001, 'neurons': 2000, 'optimizer': 'Adam'}\n","-74.083735 (8.087415) with: {'batch_size': 250, 'dropout': 0.0, 'epochs': 750, 'learning_rate': 0.001, 'neurons': 2000, 'optimizer': 'Adadelta'}\n","-67.263863 (5.827759) with: {'batch_size': 250, 'dropout': 0.0, 'epochs': 750, 'learning_rate': 0.0001, 'neurons': 1500, 'optimizer': 'Adam'}\n","-67.190702 (6.535119) with: {'batch_size': 250, 'dropout': 0.0, 'epochs': 750, 'learning_rate': 0.0001, 'neurons': 1500, 'optimizer': 'Adadelta'}\n","-68.317691 (6.388704) with: {'batch_size': 250, 'dropout': 0.0, 'epochs': 750, 'learning_rate': 0.0001, 'neurons': 2000, 'optimizer': 'Adam'}\n","-67.776702 (5.581323) with: {'batch_size': 250, 'dropout': 0.0, 'epochs': 750, 'learning_rate': 0.0001, 'neurons': 2000, 'optimizer': 'Adadelta'}\n","-69.793217 (15.081349) with: {'batch_size': 250, 'dropout': 0.0, 'epochs': 1000, 'learning_rate': 0.01, 'neurons': 1500, 'optimizer': 'Adam'}\n","-79.848696 (14.455653) with: {'batch_size': 250, 'dropout': 0.0, 'epochs': 1000, 'learning_rate': 0.01, 'neurons': 1500, 'optimizer': 'Adadelta'}\n","-75.148623 (24.441683) with: {'batch_size': 250, 'dropout': 0.0, 'epochs': 1000, 'learning_rate': 0.01, 'neurons': 2000, 'optimizer': 'Adam'}\n","-776.416809 (995.359849) with: {'batch_size': 250, 'dropout': 0.0, 'epochs': 1000, 'learning_rate': 0.01, 'neurons': 2000, 'optimizer': 'Adadelta'}\n","-76.778999 (8.582918) with: {'batch_size': 250, 'dropout': 0.0, 'epochs': 1000, 'learning_rate': 0.001, 'neurons': 1500, 'optimizer': 'Adam'}\n","-77.306096 (7.837357) with: {'batch_size': 250, 'dropout': 0.0, 'epochs': 1000, 'learning_rate': 0.001, 'neurons': 1500, 'optimizer': 'Adadelta'}\n","-80.019618 (7.537537) with: {'batch_size': 250, 'dropout': 0.0, 'epochs': 1000, 'learning_rate': 0.001, 'neurons': 2000, 'optimizer': 'Adam'}\n","-79.460454 (8.302331) with: {'batch_size': 250, 'dropout': 0.0, 'epochs': 1000, 'learning_rate': 0.001, 'neurons': 2000, 'optimizer': 'Adadelta'}\n","-73.434725 (7.417338) with: {'batch_size': 250, 'dropout': 0.0, 'epochs': 1000, 'learning_rate': 0.0001, 'neurons': 1500, 'optimizer': 'Adam'}\n","-73.663030 (6.887509) with: {'batch_size': 250, 'dropout': 0.0, 'epochs': 1000, 'learning_rate': 0.0001, 'neurons': 1500, 'optimizer': 'Adadelta'}\n","-74.198753 (5.582342) with: {'batch_size': 250, 'dropout': 0.0, 'epochs': 1000, 'learning_rate': 0.0001, 'neurons': 2000, 'optimizer': 'Adam'}\n","-74.400772 (6.186511) with: {'batch_size': 250, 'dropout': 0.0, 'epochs': 1000, 'learning_rate': 0.0001, 'neurons': 2000, 'optimizer': 'Adadelta'}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"b6b-UEOkbXDK","colab_type":"text"},"source":["# most recent gridsearch result:\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"16K0PrZDFrAG","colab_type":"text"},"source":["## Fitting the optimal model with all gridsearched parameters"]},{"cell_type":"code","metadata":{"id":"bVc2O5h6FrAH","colab_type":"code","colab":{}},"source":["#  1 HL manually chosen lowest GSCV loss\n","#{'batch_size': 500, 'dropout': 0.0, 'epochs': 250, 'learning_rate': 0.001, 'neurons': 1000, 'optimizer': 'Adagrad'}\n","# fitting the optimal GRU model with the gridsearched hyperparameters\n","GRU_model_2 = tf.keras.Sequential()\n","\n","# Add a GRU layer with 128 units (=dimensionality of the output space = number of neurons)\n","# option1: return sequences returns the hidden state output for each input time step.\n","# option2: return state returns the hidden state output and cell state for the last input time step.\n","# The output of GRU will be a 3D tensor of shape (batch_size, timesteps, 128)\n","#LSTM_model.add(tf.keras.layers.LSTM(units=1000, return_sequences = False, input_shape = (1,60), activation=my_leaky_relu, dropout = 0.0))\n","GRU_model_2.add(tf.keras.layers.GRU(units=2000, return_sequences = False, input_shape = (1,60), dropout = 0.0, activation= my_leaky_relu))\n","\n","\n","# output layer \n","GRU_model_2.add(tf.keras.layers.Dense(24))\n","# the compile() method configures the model for training\n","GRU_model_2.compile(optimizer=tf.keras.optimizers.Adadelta(learning_rate = 0.01),\n","              loss=tf.keras.losses.mean_squared_error,\n","              metrics=['mean_squared_error'])\n","GRU_model_2.fit(X_train, Y_train, epochs=750, batch_size=150, verbose=1)\n","    \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PJiLx-5tvSO-","colab_type":"code","colab":{}},"source":["#  2 HL manually chosen lowest GSCV loss\n","#{'batch_size': 500, 'dropout': 0.0, 'epochs': 250, 'learning_rate': 0.001, 'neurons': 1000, 'optimizer': 'Adagrad'}\n","# fitting the optimal GRU model with the gridsearched hyperparameters\n","Deep_GRU_model_2 = tf.keras.Sequential()\n","\n","# Add a GRU layer with 128 units (=dimensionality of the output space = number of neurons)\n","# option1: return sequences returns the hidden state output for each input time step.\n","# option2: return state returns the hidden state output and cell state for the last input time step.\n","# The output of GRU will be a 3D tensor of shape (batch_size, timesteps, 128)\n","#LSTM_model.add(tf.keras.layers.LSTM(units=1000, return_sequences = False, input_shape = (1,60), activation=my_leaky_relu, dropout = 0.0))\n","Deep_GRU_model_2.add(tf.keras.layers.GRU(units=2000, return_sequences = True, input_shape = (1,60), dropout = 0.0, activation= my_leaky_relu))\n","\n","Deep_GRU_model_2.add(tf.keras.layers.GRU(units=2000, return_sequences = False, input_shape = (1,60), dropout = 0.0, activation= my_leaky_relu))\n","\n","\n","# output layer \n","Deep_GRU_model_2.add(tf.keras.layers.Dense(24))\n","# the compile() method configures the model for training\n","Deep_GRU_model_2.compile(optimizer=tf.keras.optimizers.Adadelta(learning_rate = 0.01),\n","              loss=tf.keras.losses.mean_squared_error,\n","              metrics=['mean_squared_error'])\n","Deep_GRU_model_2.fit(X_train, Y_train, epochs=750, batch_size=150, verbose=1)\n","    \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"244iP3E0WSZz","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1600707481497,"user_tz":-120,"elapsed":2290,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}}},"source":["### 1HL GRU with hyperparameters from the new grid\n","#{'batch_size': 500, 'dropout': 0.0, 'epochs': 250, 'learning_rate': 0.001, 'neurons': 1000, 'optimizer': 'Adagrad'}\n","# fitting the optimal GRU model with the gridsearched hyperparameters\n","GRU_model = tf.keras.Sequential()\n","\n","# Add a GRU layer with 128 units (=dimensionality of the output space = number of neurons)\n","# option1: return sequences returns the hidden state output for each input time step.\n","# option2: return state returns the hidden state output and cell state for the last input time step.\n","# The output of GRU will be a 3D tensor of shape (batch_size, timesteps, 128)\n","#LSTM_model.add(tf.keras.layers.LSTM(units=1000, return_sequences = False, input_shape = (1,60), activation=my_leaky_relu, dropout = 0.0))\n","GRU_model.add(tf.keras.layers.GRU(units=2000, return_sequences = False, input_shape = (1,60), dropout = 0.0, activation=my_leaky_relu))\n","\n","\n","# output layer \n","GRU_model.add(tf.keras.layers.Dense(24))\n","# the compile() method configures the model for training\n","GRU_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate = 0.01),\n","              loss=tf.keras.losses.mean_squared_error,\n","              metrics=['mean_squared_error'])\n","GRU_model.fit(X_train, Y_train, epochs=750, batch_size=250, verbose=1)\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t6VpNkB7uyzZ","colab_type":"text"},"source":["Deep GRU network (input layer - 2 stacked GRU hidden layers - output layer)\n"]},{"cell_type":"code","metadata":{"id":"9c69dvMXuQYv","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1600707481498,"user_tz":-120,"elapsed":2285,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}}},"source":["# To stack GRU layers, we need to change the configuration of the prior GRU layer to output a 3D array as input for the subsequent layer.\n","# We can do this by setting the return_sequences argument on the layer to True (the default is False). \n","# This will return one output for each input time step and provide a 3D array.\n","\n","# fitting the optimal GRU model with the gridsearched hyperparameters\n","Deep_GRU_model = tf.keras.Sequential()\n","\n","# Add a GRU layer with 128 units (=dimensionality of the output space = number of neurons)\n","# option1: return sequences returns the hidden state output for each input time step.\n","# option2: return state returns the hidden state output and cell state for the last input time step.\n","# The output of GRU will be a 3D tensor of shape (batch_size, timesteps, 128)\n","Deep_GRU_model.add(tf.keras.layers.GRU(units=2000, return_sequences = True, input_shape = (1,60), activation=my_leaky_relu, dropout = 0.0))\n","\n","# 2nd GRU hidden layer\n","Deep_GRU_model.add(tf.keras.layers.GRU(units=2000, return_sequences = False, input_shape = (1,60), activation=my_leaky_relu, dropout = 0.0))\n","\n","\n","# output layer with 24 neurons\n","Deep_GRU_model.add(tf.keras.layers.Dense(24))\n","# the compile() method configures the model for training\n","Deep_GRU_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate = 0.01),\n","              loss=tf.keras.losses.mean_squared_error,\n","              metrics=['mean_squared_error'])\n","Deep_GRU_model.fit(X_train, Y_train, epochs=750, batch_size=250, verbose=1)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Q846PHE9ArL1","colab_type":"text"},"source":["Deep GRU network (input layer - 3 stacked GRU layers - output layer)"]},{"cell_type":"code","metadata":{"id":"okYzinVuAo5a","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1600707481498,"user_tz":-120,"elapsed":2277,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}}},"source":["# To stack GRU layers, we need to change the configuration of the prior GRU layer to output a 3D array as input for the subsequent layer.\n","# We can do this by setting the return_sequences argument on the layer to True (the default is False). \n","# This will return one output for each input time step and provide a 3D array.\n","\n","# fitting the optimal GRU model with the gridsearched hyperparameters\n","Deep_LSTM_model2 = tf.keras.Sequential()\n","\n","# Add a GRU layer with 128 units (=dimensionality of the output space = number of neurons)\n","# option1: return sequences returns the hidden state output for each input time step.\n","# option2: return state returns the hidden state output and cell state for the last input time step.\n","# The output of GRU will be a 3D tensor of shape (batch_size, timesteps, 128)\n","Deep_LSTM_model2.add(tf.keras.layers.LSTM(units=1000, return_sequences = True, input_shape = (1,60), activation=my_leaky_relu, dropout = 0.0))\n","\n","# 2nd GRU hidden layer\n","Deep_LSTM_model2.add(tf.keras.layers.LSTM(units=1000, return_sequences = True, input_shape = (1,60), activation=my_leaky_relu, dropout = 0.0))\n","\n","# 3rd GRU hidden layer\n","Deep_LSTM_model2.add(tf.keras.layers.LSTM(units=1000, return_sequences = False, input_shape = (1,60), activation=my_leaky_relu, dropout = 0.0))\n","\n","\n","# output layer with 10 ne\n","Deep_LSTM_model2.add(tf.keras.layers.Dense(24))\n","# the compile() method configures the model for training\n","Deep_LSTM_model2.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate = 0.001),\n","              loss=tf.keras.losses.mean_squared_error,\n","              metrics=['mean_squared_error'])\n","Deep_LSTM_model2.fit(X_train, Y_train, epochs=250, batch_size=500, verbose=1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FE7e5V9vFibu","colab_type":"text"},"source":["Deep GRU network (input layer - 5 stacked GRU layers - output layer)"]},{"cell_type":"code","metadata":{"id":"OikDBPZkFcJ3","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1600707481499,"user_tz":-120,"elapsed":2272,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}}},"source":["# To stack GRU layers, we need to change the configuration of the prior GRU layer to output a 3D array as input for the subsequent layer.\n","# We can do this by setting the return_sequences argument on the layer to True (the default is False). \n","# This will return one output for each input time step and provide a 3D array.\n","\n","# fitting the optimal GRU model with the gridsearched hyperparameters\n","Deep_LSTM_model3 = tf.keras.Sequential()\n","\n","# Add a GRU layer with 128 units (=dimensionality of the output space = number of neurons)\n","# option1: return sequences returns the hidden state output for each input time step.\n","# option2: return state returns the hidden state output and cell state for the last input time step.\n","# The output of GRU will be a 3D tensor of shape (batch_size, timesteps, 128)\n","Deep_LSTM_model3.add(tf.keras.layers.LSTM(units=1500, return_sequences = True, input_shape = (1,60), activation=my_leaky_relu, dropout = 0.0))\n","\n","# 2nd GRU hidden layer\n","Deep_LSTM_model3.add(tf.keras.layers.LSTM(units=1500, return_sequences = True, input_shape = (1,60), activation=my_leaky_relu, dropout = 0.0))\n","\n","# 3rd GRU hidden layer\n","Deep_LSTM_model3.add(tf.keras.layers.LSTM(units=1500, return_sequences = True, input_shape = (1,60), activation=my_leaky_relu, dropout = 0.0))\n","\n","# 4th GRU hidden layer\n","Deep_LSTM_model3.add(tf.keras.layers.LSTM(units=1500, return_sequences = True, input_shape = (1,60), activation=my_leaky_relu, dropout = 0.0))\n","\n","# 5th GRU hidden layer\n","Deep_LSTM_model3.add(tf.keras.layers.LSTM(units=1500, return_sequences = False, input_shape = (1,60), activation=my_leaky_relu, dropout = 0.0))\n","\n","# output layer \n","Deep_LSTM_model3.add(tf.keras.layers.Dense(24))\n","# the compile() method configures the model for training\n","Deep_LSTM_model3.compile(optimizer=tf.keras.optimizers.Adam(learning_rate = 0.001),\n","              loss=tf.keras.losses.mean_squared_error,\n","              metrics=['mean_squared_error'])\n","Deep_LSTM_model3.fit(X_train, Y_train, epochs=500, batch_size=250, verbose=1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ut4lCCVqFrAT","colab_type":"text"},"source":["## Undoing the normalization, making predictions and computing the test error"]},{"cell_type":"code","metadata":{"id":"qpJXmKeLFrAW","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1600707481500,"user_tz":-120,"elapsed":2271,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}}},"source":["# making predictions (regular GRU)\n","y_train_pred = GRU_model.predict(X_train)\n","y_test_pred = GRU_model.predict(X_test)\n","\n","# making predictions (deep GRU 2 hidden layers)\n","y_train_pred_deep = Deep_GRU_model.predict(X_train)\n","y_test_pred_deep = Deep_GRU_model.predict(X_test)\n","\n","# making predictions (deep GRU 3 hidden layers)\n","y_train_pred_deep2 = Deep_LSTM_model2.predict(X_train)\n","y_test_pred_deep2 = Deep_LSTM_model2.predict(X_test)\n","\n","# making predictions (deep GRU 5 hidden layers)\n","y_train_pred_deep3 = Deep_LSTM_model3.predict(X_train)\n","y_test_pred_deep3 = Deep_LSTM_model3.predict(X_test)\n","\n","# invert predictions\n","y_train_pred = scaler.inverse_transform(y_train_pred)\n","y_test_pred = scaler.inverse_transform(y_test_pred)\n","\n","#invert originals\n","y_train_orig = scaler.inverse_transform(y_train)\n","y_test_orig = scaler.inverse_transform(y_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A7XL5gPDun4V","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1600707481505,"user_tz":-120,"elapsed":2225,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}}},"source":["# MSE GRU model 2 forecast\n","mse_GRU = mean_squared_error(Y_test, y_test_pred2)\n","mse_GRU"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mfQvMAh6umyJ","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1600707481506,"user_tz":-120,"elapsed":2220,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}}},"source":["# RMSE GRU model 2 forecast\n","rmse_GRU = sqrt(mse_GRU)\n","rmse_GRU"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iZ2nWnA7umv2","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1600707481506,"user_tz":-120,"elapsed":2215,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}}},"source":["# mae GRU model 2\n","mae_LSTM = mean_absolute_error(Y_test, y_test_pred2)\n","mae_LSTM"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BsdH858tu17j","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1600707481507,"user_tz":-120,"elapsed":2213,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}}},"source":["# custom MAPE function\n","def mean_absolute_percentage_error(y_true, y_pred): \n","    \"\"\"Calculates MAPE given y_true and y_pred\"\"\"\n","    y_true, y_pred = np.array(y_true), np.array(y_pred)\n","    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n","\n","y_true = Y_test\n","y_pred = y_test_pred2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1AXo1ZHfu15I","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1600707481507,"user_tz":-120,"elapsed":2207,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}}},"source":["# MAPE GRU model 2 1 HL\n","\n","mean_absolute_percentage_error(y_true,y_pred)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WB08J-IQwcvr","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1600707481509,"user_tz":-120,"elapsed":2193,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}}},"source":["# MSE deep GRU model 2 forecast\n","mse_GRU = mean_squared_error(Y_test, y_test_pred_deep2)\n","mse_GRU"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aKyWvjkmwpfl","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1600707481509,"user_tz":-120,"elapsed":2186,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}}},"source":["# RMSE deep GRU model 2 forecast\n","rmse_GRU = sqrt(mse_GRU)\n","rmse_GRU"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K5ionst8yXTM","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1600707481510,"user_tz":-120,"elapsed":2180,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}}},"source":["# mae deep GRU model 2\n","mae_LSTM = mean_absolute_error(Y_test, y_test_pred_deep2)\n","mae_LSTM"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IHU4to3eyXYh","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1600707481510,"user_tz":-120,"elapsed":2177,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}}},"source":["# custom MAPE function\n","def mean_absolute_percentage_error(y_true, y_pred): \n","    \"\"\"Calculates MAPE given y_true and y_pred\"\"\"\n","    y_true, y_pred = np.array(y_true), np.array(y_pred)\n","    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n","\n","y_true = Y_test\n","y_pred = y_test_pred_deep2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XndMZQ-4yXW1","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1600707481511,"user_tz":-120,"elapsed":2171,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}}},"source":["# MAPE GRU model 2 2 HL\n","\n","mean_absolute_percentage_error(y_true,y_pred)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pBGX37wrwcs3","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1600707481511,"user_tz":-120,"elapsed":2169,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QVr3MTSVFrAw","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1600707481512,"user_tz":-120,"elapsed":2163,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}}},"source":["# MSE  forecast\n","mse_GRU = mean_squared_error(Y_test, y_test_pred)\n","mse_GRU"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p5sQoY3vFrA2","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1600707481512,"user_tz":-120,"elapsed":2156,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}}},"source":["# RMSE GRU forecast\n","rmse_GRU = sqrt(mse_GRU)\n","rmse_GRU"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EDmw9BJOFrA6","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1600707481512,"user_tz":-120,"elapsed":2149,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}}},"source":["# mae GRU\n","mae_LSTM = mean_absolute_error(Y_test, y_test_pred)\n","mae_LSTM"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NrCfCJ6wGNvB","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1600707481513,"user_tz":-120,"elapsed":2148,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}}},"source":["# custom MAPE function\n","def mean_absolute_percentage_error(y_true, y_pred): \n","    \"\"\"Calculates MAPE given y_true and y_pred\"\"\"\n","    y_true, y_pred = np.array(y_true), np.array(y_pred)\n","    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n","\n","y_true = Y_test\n","y_pred = y_test_pred\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tuRWnDRv_3yg","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1600707481513,"user_tz":-120,"elapsed":2141,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}}},"source":["# MAPE GRU 1 HL\n","y_true = Y_test\n","y_pred = y_test_pred\n","\n","mean_absolute_percentage_error(y_true,y_pred)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sUiTMR03v-2a","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1600707481515,"user_tz":-120,"elapsed":2122,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}}},"source":["# MSE Deep GRU forecast (2HL)\n","mse_GRU1 = mean_squared_error(Y_test, y_test_pred_deep)\n","mse_GRU1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FlUIP0qov-zx","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1600707481515,"user_tz":-120,"elapsed":2116,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}}},"source":["# RMSE Deep GRU forecast (2HL)\n","rmse_GRU1 = sqrt(mse_GRU1)\n","rmse_GRU1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qDnRzfXlwEck","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1600707481516,"user_tz":-120,"elapsed":2110,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}}},"source":["# mae DeepGRU (2HL)\n","mae_GRU1 = mean_absolute_error(Y_test, y_test_pred_deep)\n","mae_GRU1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iCdmfI_wGayY","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1600707481516,"user_tz":-120,"elapsed":2104,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}}},"source":["# MAPE GRU 2 HL\n","y_true = Y_test\n","y_pred = y_test_pred_deep\n","\n","mean_absolute_percentage_error(y_true,y_pred)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rQEP3CwsBWki","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1600707481517,"user_tz":-120,"elapsed":2098,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}}},"source":["# MSE Deep GRU forecast (3HL)\n","mse_LSTM2 = mean_squared_error(Y_test, y_test_pred_deep2)\n","mse_LSTM2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xCmbK3UsBWog","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1600707481517,"user_tz":-120,"elapsed":2091,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}}},"source":["# RMSE Deep GRU forecast (3HL)\n","rmse_LSTM2 = sqrt(mse_LSTM2)\n","rmse_LSTM2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uGlk59RQBWiD","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1600707481517,"user_tz":-120,"elapsed":2085,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}}},"source":["# mae DeepGRU (3HL)\n","mae_LSTM2 = mean_absolute_error(Y_test, y_test_pred_deep2)\n","mae_LSTM2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"puNhpzj_FUu5","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1600707481518,"user_tz":-120,"elapsed":2079,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}}},"source":["# MSE Deep LSTM forecast (5HL)\n","mse_LSTM3 = mean_squared_error(Y_test, y_test_pred_deep3)\n","mse_LSTM3"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2DPczsZ5Gl99","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1600707481518,"user_tz":-120,"elapsed":2073,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}}},"source":["# RMSE Deep GRU forecast (5HL)\n","rmse_LSTM3 = sqrt(mse_LSTM3)\n","rmse_LSTM3"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XD0DfHoyGmCh","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1600707481519,"user_tz":-120,"elapsed":2069,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}}},"source":["# mae DeepGRU (5HL)\n","mae_LSTM2 = mean_absolute_error(Y_test, y_test_pred_deep3)\n","mae_LSTM2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vcSdCM1_ACTO","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1600707481519,"user_tz":-120,"elapsed":2062,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}}},"source":["# MAPE GRU 3 HL\n","y_true = Y_test\n","y_pred = y_test_pred_deep2\n","\n","mean_absolute_percentage_error(y_true,y_pred)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Sho0zOUtAGyD","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1600707481520,"user_tz":-120,"elapsed":2056,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}}},"source":["# MAPE GRU 5 HL\n","y_true = Y_test\n","y_pred = y_test_pred_deep3\n","\n","mean_absolute_percentage_error(y_true,y_pred)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XSfNzxfqFrDq","colab_type":"text"},"source":["## Prediction intervals using quantile regression"]},{"cell_type":"code","metadata":{"id":"xhVawXS_FrDq","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1600707481520,"user_tz":-120,"elapsed":2054,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}}},"source":["# quantile regression loss = tilted loss = pinball loss\n","def tilted_loss(q,y,f):\n","    e = (y-f)\n","    return K.mean(K.maximum(q*e, (q-1)*e), axis=-1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oQLDhaUFqVHl","colab_type":"text"},"source":["2 separate PI networks 1 hidden layer GRU"]},{"cell_type":"code","metadata":{"id":"dzisxiJjFrDw","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1600707481521,"user_tz":-120,"elapsed":2049,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}}},"source":["## build lower bound with different loss (95% PI)\n","q = 0.025\n","\n","\n","# fitting the GRU model with the gridsearched hyperparameters\n","lower_PI_model = tf.keras.Sequential()\n","\n","# Add a GRU layer with 128 units (=dimensionality of the output space = number of neurons)\n","# option1: return sequences returns the hidden state output for each input time step.\n","# option2: return state returns the hidden state output and cell state for the last input time step.\n","# The output of GRU will be a 3D tensor of shape (batch_size, timesteps, 128)\n","lower_PI_model.add(tf.keras.layers.GRU(units=2000, return_sequences = False, input_shape = (1,60), activation=my_leaky_relu, dropout = 0.0))\n","\n","# output layer with 10 neurons\n","lower_PI_model.add(tf.keras.layers.Dense(24))\n","# the compile() method configures the model for training\n","lower_PI_model.compile(optimizer=tf.keras.optimizers.Adadelta(learning_rate = 0.01),\n","              loss=lambda y,f: tilted_loss(q,y,f))\n","lower_PI_model.fit(X_train, Y_train, epochs=300, batch_size=150, verbose=1)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SUMSKk-2FrDz","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1600707481521,"user_tz":-120,"elapsed":2043,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}}},"source":["## build upper bound with different loss (95% PI)\n","q = 0.975\n","\n","\n","# fitting the GRU model with the gridsearched hyperparameters\n","upper_PI_model = tf.keras.Sequential()\n","\n","# Add a GRU layer with 128 units (=dimensionality of the output space = number of neurons)\n","# option1: return sequences returns the hidden state output for each input time step.\n","# option2: return state returns the hidden state output and cell state for the last input time step.\n","# The output of GRU will be a 3D tensor of shape (batch_size, timesteps, 128)\n","upper_PI_model.add(tf.keras.layers.GRU(units=2000, return_sequences = False, input_shape = (1,60), activation=my_leaky_relu, dropout = 0.0))\n","\n","# output layer with 10 neurons\n","upper_PI_model.add(tf.keras.layers.Dense(24))\n","# the compile() method configures the model for training\n","upper_PI_model.compile(optimizer=tf.keras.optimizers.Adadelta(learning_rate = 0.01),\n","              loss=lambda y,f: tilted_loss(q,y,f))\n","upper_PI_model.fit(X_train, Y_train, epochs=300, batch_size=150, verbose=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aeD6Oo4aFrD3","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1600707481522,"user_tz":-120,"elapsed":2042,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}}},"source":["# predictions from PI models\n","\n","lower_pred = lower_PI_model.predict(X_test)\n","upper_pred = upper_PI_model.predict(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dwxptO4IyGwr","colab_type":"text"},"source":["PIs for the DLSTM model (2HL) two networks"]},{"cell_type":"code","metadata":{"id":"I4Dd2L2LzKL3","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1600707481523,"user_tz":-120,"elapsed":2020,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}}},"source":["## build lower bound with different loss (95% PI)\n","q = 0.025\n","\n","\n","# fitting the GRU model with the gridsearched hyperparameters\n","lower_PI_model_deep = tf.keras.Sequential()\n","\n","# Add a GRU layer with 128 units (=dimensionality of the output space = number of neurons)\n","# option1: return sequences returns the hidden state output for each input time step.\n","# option2: return state returns the hidden state output and cell state for the last input time step.\n","# The output of GRU will be a 3D tensor of shape (batch_size, timesteps, 128)\n","lower_PI_model_deep.add(tf.keras.layers.GRU(units=1000, return_sequences = True, input_shape = (1,60), activation=my_leaky_relu, dropout = 0.0))\n","\n","lower_PI_model_deep.add(tf.keras.layers.GRU(units=1000, return_sequences = False, input_shape = (1,60), activation=my_leaky_relu, dropout = 0.0))\n","\n","\n","# output layer with 10 neurons\n","lower_PI_model_deep.add(tf.keras.layers.Dense(24))\n","# the compile() method configures the model for training\n","lower_PI_model_deep.compile(optimizer=tf.keras.optimizers.Adadelta(learning_rate = 0.01),\n","              loss=lambda y,f: tilted_loss(q,y,f))\n","lower_PI_model_deep.fit(X_train, Y_train, epochs=300, batch_size=200, verbose=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DnYAXMD2zZyv","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1600707481525,"user_tz":-120,"elapsed":2016,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}}},"source":["## build upper bound with different loss (95% PI)\n","q = 0.975\n","\n","\n","# fitting the GRU model with the gridsearched hyperparameters\n","upper_PI_model_deep = tf.keras.Sequential()\n","\n","# Add a GRU layer with 128 units (=dimensionality of the output space = number of neurons)\n","# option1: return sequences returns the hidden state output for each input time step.\n","# option2: return state returns the hidden state output and cell state for the last input time step.\n","# The output of GRU will be a 3D tensor of shape (batch_size, timesteps, 128)\n","upper_PI_model_deep.add(tf.keras.layers.GRU(units=1000, return_sequences = True, input_shape = (1,60), activation=my_leaky_relu, dropout = 0.0))\n","\n","upper_PI_model_deep.add(tf.keras.layers.GRU(units=1000, return_sequences = False, input_shape = (1,60), activation=my_leaky_relu, dropout = 0.0))\n","\n","\n","# output layer with 10 neurons\n","upper_PI_model_deep.add(tf.keras.layers.Dense(24))\n","# the compile() method configures the model for training\n","upper_PI_model_deep.compile(optimizer=tf.keras.optimizers.Adadelta(learning_rate = 0.01),\n","              loss=lambda y,f: tilted_loss(q,y,f))\n","upper_PI_model_deep.fit(X_train, Y_train, epochs=300, batch_size=200, verbose=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tYJQR_olznz6","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1600707481525,"user_tz":-120,"elapsed":2014,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}}},"source":["# predictions from PI models\n","\n","lower_pred_deep = lower_PI_model_deep.predict(X_test)\n","upper_pred_deep = upper_PI_model_deep.predict(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qY2nsx-sVT7h","colab_type":"text"},"source":["# Exporting the PI bounds"]},{"cell_type":"code","metadata":{"id":"PdfQ7FPRVI6Q","colab_type":"code","colab":{}},"source":["upper_pred_1hl = pd.Series(upper_pred[0])\n","lower_pred_1hl = pd.Series(lower_pred[0])\n","upper_pred_2hl = pd.Series(upper_pred_deep[0])\n","lower_pred_2hl = pd.Series(lower_pred_deep[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oj4t9XkqVI9Y","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":802},"executionInfo":{"status":"ok","timestamp":1599644113585,"user_tz":-120,"elapsed":1144,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"26d65001-ac5e-4e93-89b7-43f5940ea627"},"source":["# export the PI bounds for plotting in R\n","GRU_ems_pi_df = pd.DataFrame()\n","\n","\n","\n","# adding a column with the test data\n","GRU_ems_pi_df[\"upper_bound_1hl\"] = upper_pred_1hl\n","GRU_ems_pi_df[\"lower_bound_1hl\"] = lower_pred_1hl\n","GRU_ems_pi_df[\"upper_bound_2hl\"] = upper_pred_2hl\n","GRU_ems_pi_df[\"lower_bound_2hl\"] = lower_pred_2hl\n","\n","\n","GRU_ems_pi_df\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>upper_bound_1hl</th>\n","      <th>lower_bound_1hl</th>\n","      <th>upper_bound_2hl</th>\n","      <th>lower_bound_2hl</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>50.336510</td>\n","      <td>22.262304</td>\n","      <td>50.464931</td>\n","      <td>22.007679</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>46.607979</td>\n","      <td>21.321659</td>\n","      <td>46.405609</td>\n","      <td>17.912231</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>41.474297</td>\n","      <td>15.419744</td>\n","      <td>40.987724</td>\n","      <td>13.768996</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>38.642899</td>\n","      <td>9.931201</td>\n","      <td>44.039425</td>\n","      <td>13.168715</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>37.261223</td>\n","      <td>13.019662</td>\n","      <td>32.470146</td>\n","      <td>13.720415</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>40.333721</td>\n","      <td>14.157906</td>\n","      <td>36.401173</td>\n","      <td>12.688701</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>43.842426</td>\n","      <td>14.100899</td>\n","      <td>44.542225</td>\n","      <td>16.298822</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>46.362923</td>\n","      <td>18.130318</td>\n","      <td>45.785686</td>\n","      <td>18.691341</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>56.363609</td>\n","      <td>21.443565</td>\n","      <td>56.101830</td>\n","      <td>20.461889</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>66.476547</td>\n","      <td>25.135046</td>\n","      <td>65.836899</td>\n","      <td>24.391270</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>69.628220</td>\n","      <td>25.423382</td>\n","      <td>69.937202</td>\n","      <td>25.048899</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>68.793114</td>\n","      <td>29.461575</td>\n","      <td>66.658646</td>\n","      <td>29.982601</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>68.253738</td>\n","      <td>31.104227</td>\n","      <td>63.623474</td>\n","      <td>30.027475</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>65.592087</td>\n","      <td>30.307741</td>\n","      <td>65.336975</td>\n","      <td>30.621971</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>65.024399</td>\n","      <td>28.282164</td>\n","      <td>66.809891</td>\n","      <td>31.399714</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>65.395332</td>\n","      <td>30.881132</td>\n","      <td>69.260452</td>\n","      <td>35.003674</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>64.960907</td>\n","      <td>33.620155</td>\n","      <td>68.556114</td>\n","      <td>37.728039</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>67.558235</td>\n","      <td>34.031586</td>\n","      <td>66.426514</td>\n","      <td>32.971291</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>65.274666</td>\n","      <td>35.528313</td>\n","      <td>67.346634</td>\n","      <td>38.900841</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>64.797874</td>\n","      <td>36.225853</td>\n","      <td>61.773617</td>\n","      <td>35.747517</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>64.781441</td>\n","      <td>36.549976</td>\n","      <td>61.192493</td>\n","      <td>36.444992</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>58.861729</td>\n","      <td>31.808872</td>\n","      <td>57.546558</td>\n","      <td>30.890997</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>53.523762</td>\n","      <td>27.070816</td>\n","      <td>52.907829</td>\n","      <td>24.500307</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>53.811287</td>\n","      <td>19.201410</td>\n","      <td>48.127945</td>\n","      <td>18.470308</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    upper_bound_1hl  lower_bound_1hl  upper_bound_2hl  lower_bound_2hl\n","0         50.336510        22.262304        50.464931        22.007679\n","1         46.607979        21.321659        46.405609        17.912231\n","2         41.474297        15.419744        40.987724        13.768996\n","3         38.642899         9.931201        44.039425        13.168715\n","4         37.261223        13.019662        32.470146        13.720415\n","5         40.333721        14.157906        36.401173        12.688701\n","6         43.842426        14.100899        44.542225        16.298822\n","7         46.362923        18.130318        45.785686        18.691341\n","8         56.363609        21.443565        56.101830        20.461889\n","9         66.476547        25.135046        65.836899        24.391270\n","10        69.628220        25.423382        69.937202        25.048899\n","11        68.793114        29.461575        66.658646        29.982601\n","12        68.253738        31.104227        63.623474        30.027475\n","13        65.592087        30.307741        65.336975        30.621971\n","14        65.024399        28.282164        66.809891        31.399714\n","15        65.395332        30.881132        69.260452        35.003674\n","16        64.960907        33.620155        68.556114        37.728039\n","17        67.558235        34.031586        66.426514        32.971291\n","18        65.274666        35.528313        67.346634        38.900841\n","19        64.797874        36.225853        61.773617        35.747517\n","20        64.781441        36.549976        61.192493        36.444992\n","21        58.861729        31.808872        57.546558        30.890997\n","22        53.523762        27.070816        52.907829        24.500307\n","23        53.811287        19.201410        48.127945        18.470308"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"code","metadata":{"id":"iCyut6YRYH6b","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1599644118565,"user_tz":-120,"elapsed":2631,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"93b9f442-1df2-4a5c-929d-c24a5cbacb9a"},"source":["# export the GRU predictions and the test data to google drive\n","from google.colab import  drive\n","\n","drive.mount('/drive')\n","\n","GRU_ems_pi_df.to_csv('/drive/My Drive/Colab Notebooks/GRU_ems_pis.csv', index=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rZum__7f0Z-V","colab_type":"text"},"source":["PI measure calculations"]},{"cell_type":"code","metadata":{"id":"pnqrVGOc0dA6","colab_type":"code","colab":{}},"source":["def PCIP(upper, lower, test_set):\n","    n = len(Y_test[0,:])\n","    count = 0\n","    PCIP = 0\n","    \n","    for i in range(n):\n","        if (upper[0,i] > test_set[0,i] and lower[0,i] < test_set[0,i]):\n","            count = count + 1 \n","            \n","    PCIP = count/n\n","    return PCIP"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dC2EtL9Nzuun","colab_type":"code","colab":{}},"source":["# reshape PI values\n","lower_PI_values_2HL = lower_PI_preds_2HL_95.values.reshape(1,24)\n","upper_PI_values_2HL = upper_PI_preds_2HL_95.values.reshape(1,24)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IuQ4GqC60h4I","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593530617880,"user_tz":-120,"elapsed":892,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"b8b84850-463b-484c-bc01-4768a3e5af68"},"source":["# DGRU (2HL) \n","#PCIP(upper = upper_pred_dgru3, lower = lower_pred_dgru3, test_set = Y_test)\n","PCIP(upper = upper_PI_values_2HL, lower = lower_PI_values_2HL, test_set = Y_test)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9583333333333334"]},"metadata":{"tags":[]},"execution_count":119}]},{"cell_type":"code","metadata":{"id":"byq8hvuB0h8Z","colab_type":"code","colab":{}},"source":["def MPIW(upper, lower):\n","    n = len(upper[0,:])\n","    diff = 0\n","    MPIW = 0\n","    \n","    for i in range(n):\n","        diff = diff + (upper[0,i] - lower[0,i])\n","    \n","    MPIW = diff/n\n","    return MPIW"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aeBprJQZ0iG-","colab_type":"code","colab":{}},"source":["# MPIW for the best DGRU model (2HL)\n","MPIW(upper = upper_PI_values_2HL, lower = lower_PI_values_2HL)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TlKA9YunFrEK","colab_type":"text"},"source":["# Plotting the predictions"]},{"cell_type":"markdown","metadata":{"id":"rH7SqfiDriy1","colab_type":"text"},"source":["plot 2 PI networks"]},{"cell_type":"code","metadata":{"id":"eaTDJbc9FrEK","colab_type":"code","colab":{}},"source":["# GRU model (1HL) predictions vs test data\n","\n","plt.xlim(0,24)\n","#plt.plot(np.transpose(y_test_pred2), label=\"GRU_predictions\")\n","plt.plot(np.transpose(Y_test), label = \"Test data\")\n","plt.fill_between(x = np.arange(0,24), y1= np.transpose(lower_pred).reshape(24), y2=np.transpose(upper_pred).reshape(24), color = \"b\", alpha = 0.10)\n","\n","# axis labels, title and legend\n","plt.xlabel('Time steps')\n","plt.ylabel(\"Traffic flow\")\n","plt.title(\"LSTM predictions vs test data\", fontweight=\"bold\")\n","#legend = plt.legend([\"LSTM\" predictions\",\"Test data\",\"95% PI\"],loc='lower right')\n","\n","#save_results_to = '/Users/Manu/Dropbox/MScThesis-Conor-Manu/Latex/'\n","#tkz.save(save_results_to + \"GRU_predictions.tex\")\n","\n","plt.show()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x7CFK1YeQ8gb","colab_type":"code","colab":{}},"source":["# GRU model (2HL) predictions vs test data\n","\n","plt.xlim(0,24)\n","#plt.plot(np.transpose(y_test_pred_deep2), label=\"GRU_predictions\")\n","plt.plot(np.transpose(Y_test), label = \"Test data\")\n","plt.fill_between(x = np.arange(0,24), y1= np.transpose(lower_pred_deep).reshape(24), y2=np.transpose(upper_pred_deep).reshape(24), color = \"b\", alpha = 0.10)\n","\n","# axis labels, title and legend\n","plt.xlabel('Time steps')\n","plt.ylabel(\"Traffic flow\")\n","plt.title(\"LSTM predictions vs test data\", fontweight=\"bold\")\n","#legend = plt.legend([\"LSTM\" predictions\",\"Test data\",\"95% PI\"],loc='lower right')\n","\n","#save_results_to = '/Users/Manu/Dropbox/MScThesis-Conor-Manu/Latex/'\n","#tkz.save(save_results_to + \"GRU_predictions.tex\")\n","\n","plt.show()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qZYTUYz8rf3E","colab_type":"text"},"source":["plot single PI network"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"By29Qv7OrcgX","colab":{}},"source":["# GRU model (1HL) predictions vs test data\n","\n","plt.xlim(0,24)\n","plt.plot(np.transpose(y_test_pred), label=\"GRU_predictions\")\n","plt.plot(np.transpose(Y_test), label = \"Test data\")\n","#plt.fill_between(x = np.arange(0,24), y1= lower_PI_preds_95, y2= upper_PI_preds_95, color = 'xkcd:sky blue')\n","\n","# axis labels, title and legend\n","plt.xlabel('Time steps')\n","plt.ylabel(\"Traffic flow\")\n","plt.title(\"GRU predictions vs test data\", fontweight=\"bold\")\n","legend = plt.legend([\"GRU predictions\",\"Test data\",\"95% PI\"],loc='lower right')\n","\n","#save_results_to = '/Users/Manu/Dropbox/MScThesis-Conor-Manu/Latex/'\n","#tkz.save(save_results_to + \"GRU_predictions.tex\")\n","\n","plt.show()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8e_cQ4I1wkQp","colab_type":"code","colab":{}},"source":["# Deep GRU model (2HL) predictions vs test data (1 PI network)\n","\n","plt.xlim(0,24)\n","plt.plot(np.transpose(y_test_pred_deep), label=\"Deep GRU_predictions\")\n","plt.plot(np.transpose(Y_test), label = \"Test data\")\n","#plt.fill_between(x = np.arange(0,24), y1= lower_PI_preds_2HL_95, y2= upper_PI_preds_2HL_95, color = 'xkcd:sky blue')\n","\n","# axis labels, title and legend\n","plt.xlabel('Time steps')\n","plt.ylabel(\"Traffic flow\")\n","plt.title(\"Deep GRU predictions (2HL) vs test data\", fontweight=\"bold\")\n","legend = plt.legend([\"GRU predictions\",\"Test data\",\"95% PI\"],loc='lower right')\n","\n","#save_results_to = '/Users/Manu/Dropbox/MScThesis-Conor-Manu/Latex/'\n","#tkz.save(save_results_to + \"GRU_predictions.tex\")\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"En9xagzpBw7c","colab_type":"code","colab":{}},"source":["# Deep GRU model (3HL) predictions vs test data\n","\n","plt.xlim(0,24)\n","plt.plot(np.transpose(y_test_pred_deep2), label=\"Deep GRU_predictions\")\n","plt.plot(np.transpose(Y_test), label = \"Test data\")\n","#plt.fill_between(x = np.arange(0,24), y1= np.transpose(lower_pred_dgru3).reshape(24), y2=np.transpose(upper_pred_dgru3).reshape(24), color = \"b\", alpha = 0.10)\n","\n","# axis labels, title and legend\n","plt.xlabel('Time steps')\n","plt.ylabel(\"Traffic flow\")\n","plt.title(\"Deep GRU predictions (3HL) vs test data\", fontweight=\"bold\")\n","legend = plt.legend([\"GRU predictions\",\"Test data\",\"95% PI\"],loc='lower right')\n","\n","#save_results_to = '/Users/Manu/Dropbox/MScThesis-Conor-Manu/Latex/'\n","#tkz.save(save_results_to + \"GRU_predictions.tex\")\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6cv65hSQHLVx","colab_type":"code","colab":{}},"source":["# Deep GRU model (5HL) predictions vs test data\n","\n","plt.xlim(0,24)\n","plt.plot(np.transpose(y_test_pred_deep3), label=\"Deep GRU_predictions\")\n","plt.plot(np.transpose(Y_test), label = \"Test data\")\n","#plt.fill_between(x = np.arange(0,24), y1= np.transpose(lower_pred).reshape(24), y2=np.transpose(upper_pred).reshape(24), color = \"b\", alpha = 0.10)\n","\n","# axis labels, title and legend\n","plt.xlabel('Time steps')\n","plt.ylabel(\"Traffic flow\")\n","plt.title(\"Deep GRU predictions (5HL) vs test data\", fontweight=\"bold\")\n","legend = plt.legend([\"GRU predictions\",\"Test data\",\"95% PI\"],loc='lower right')\n","\n","#save_results_to = '/Users/Manu/Dropbox/MScThesis-Conor-Manu/Latex/'\n","#tkz.save(save_results_to + \"GRU_predictions.tex\")\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3O1yhotJTObV","colab_type":"text"},"source":["# Exporting the point forecasts\n"]},{"cell_type":"code","metadata":{"id":"nPW_iLVhkFdZ","colab_type":"code","colab":{}},"source":["GRU_ems_preds = pd.Series(y_test_pred2[0])\n","GRU_ems_preds_deep = pd.Series(y_test_pred_deep2[0])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rWUTRXRTTYL-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1599637204198,"user_tz":-120,"elapsed":1571,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"08fec785-aee8-46a1-ea13-3cc54a4a54f1"},"source":["# export the GRU predictions and the test data to google drive\n","from google.colab import  drive\n","\n","drive.mount('/drive')\n","\n","GRU_ems_preds.to_csv('/drive/My Drive/Colab Notebooks/GRU_ems_preds.csv', index=False)\n","GRU_ems_preds_deep.to_csv('/drive/My Drive/Colab Notebooks/GRU_ems_preds_deep.csv', index=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jE9qwbVBwlqj","colab_type":"text"},"source":["Plotting the Predictions from the Deep GRU Model"]},{"cell_type":"code","metadata":{"id":"Lh5Z4ogKFrEl","colab_type":"code","colab":{}},"source":["plt.xlim(0,24)\n","plt.plot(np.transpose(y_test_pred), label=\"GRU_predictions\")\n","plt.plot(np.transpose(Y_test), label = \"Test data\")\n","plt.fill_between(x = np.arange(0,24), y1= np.transpose(lower_pred).reshape(24), y2=np.transpose(upper_pred).reshape(24), color = \"b\", alpha = 0.10)\n","\n","# axis labels, title and legend\n","plt.xlabel('Time steps')\n","plt.ylabel(\"Traffic flow\")\n","plt.title(\"GRU predictions vs test data (regularized)\", fontweight=\"bold\")\n","legend = plt.legend([\"GRU predictions\",\"Test data\",\"95% PI\"],loc='lower right')\n","\n","#save_results_to = '/Users/Manu/Dropbox/MScThesis-Conor-Manu/Latex/'\n","#tkz.save(save_results_to + \"GRU_predictions.tex\")\n","\n","plt.show()"],"execution_count":null,"outputs":[]}]}