{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"LGBM_one year_traffic.ipynb","provenance":[{"file_id":"1B3RwPaDkpiRYdoj7BB0XD4fa9lmK3xOk","timestamp":1596382012502}],"collapsed_sections":["pfln67RVUOJK"],"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"y6YsUR3mUOEy","colab_type":"text"},"source":["# LGBM/XGBoosting for the traffic flow data"]},{"cell_type":"markdown","metadata":{"id":"3d2qnLn3UOE1","colab_type":"text"},"source":["https://www.kaggle.com/robikscube/tutorial-time-series-forecasting-with-xgboost"]},{"cell_type":"markdown","metadata":{"id":"4jMJD4_iUOE4","colab_type":"text"},"source":["Importing libraries"]},{"cell_type":"code","metadata":{"id":"2KN6E8MKUOE7","colab_type":"code","colab":{}},"source":["# general routine set up:\n","\n","# ignore warnings\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","# get wd and change the wd plus import libraries\n","import os\n","os.getcwd()\n","#os.chdir(\"/Users/Manu/Dropbox/CBS MSc Thesis Research Folder/DATA & Code/Model Specific Notebooks\")\n","\n","\n","# standard\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt \n","%matplotlib inline\n","from math import sqrt\n","import pickle\n","\n","# ML\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.model_selection import TimeSeriesSplit\n","from sklearn.model_selection import train_test_split\n","import xgboost as xgb\n","from xgboost import plot_importance, plot_tree\n","from sklearn.metrics import mean_squared_error, mean_absolute_error\n","from sklearn.multioutput import MultiOutputRegressor\n","import tensorflow.keras.backend as K\n","from lightgbm import LGBMRegressor"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JDuBnHiZUOFN","colab_type":"text"},"source":["Loading the data"]},{"cell_type":"code","metadata":{"id":"aIizwmU9XRQK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1598294156059,"user_tz":-120,"elapsed":20522,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"14881f4a-f07b-4a97-d015-a4c6e7f07365"},"source":["# this allows for accessing files stored in your google drive using the path \"/gdrive/\"\n","# mounting google drive locally:\n","\n","from google.colab import drive\n","drive.mount('/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9R3DJqolXY_e","colab_type":"code","colab":{}},"source":["#loading the hourly traffic data (1 year of data; June 2018 to June 2019)\n","filename = \"/gdrive/My Drive/Colab Notebooks/taxi_series_H\"\n","infile = open(filename,'rb')\n","taxidemand_ts = pickle.load(infile)\n","infile.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VWye-hnAzNq7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598294163538,"user_tz":-120,"elapsed":1280,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"884a4e7c-a0ab-440f-adf2-83a94399b385"},"source":["taxidemand_ts.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(8760,)"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"Z-AofGAaUOFY","colab_type":"text"},"source":["Preprocessing: already done\n"]},{"cell_type":"markdown","metadata":{"id":"exVAFiNZUOF4","colab_type":"text"},"source":["Time Series data must be re-framed as a supervised learning dataset before we can start using machine learning algorithms.  \n","There is no concept of input and output features in time series. Instead, we must choose the variable to be predicted and use feature engineering to construct all of the inputs that will be used to make predictions for future time steps."]},{"cell_type":"markdown","metadata":{"id":"9atRO7l0UOF7","colab_type":"text"},"source":["## Feature Engineering for Times Series"]},{"cell_type":"markdown","metadata":{"id":"ameUwQssUOF8","colab_type":"text"},"source":["[feature_eng_ts.png](attachment:feature_eng_ts.png)"]},{"cell_type":"markdown","metadata":{"id":"Wu-0lspKUOF9","colab_type":"text"},"source":["In this tutorial, we will look at three classes of features that we can create from our time series dataset:\n","\n","    Date Time Features: these are components of the time step itself for each observation.\n","    Lag Features: these are values at prior time steps.\n","    Window Features: these are a summary of values over a fixed window of prior time steps.\n"]},{"cell_type":"markdown","metadata":{"id":"sYbH0vQDUOF_","colab_type":"text"},"source":["Lag features are the classical way that time series forecasting problems are transformed into supervised learning problems."]},{"cell_type":"markdown","metadata":{"id":"kBbg_jTeUOGA","colab_type":"text"},"source":["The goal of feature engineering is to provide strong and ideally simple relationships between new input features and the output feature for the supervised learning algorithm to model."]},{"cell_type":"markdown","metadata":{"id":"eInrwANETsUE","colab_type":"text"},"source":["**Preprocessing for Multioutput Forecasting**"]},{"cell_type":"markdown","metadata":{"id":"PBb7LhJzUcKk","colab_type":"text"},"source":["### Preprocessing (For multi output model)\n","For supervised machine learning methods to work on time series it is necessary to do a certain amount of preprocessing. This includes feature generation such as embedding(lags). "]},{"cell_type":"code","metadata":{"id":"NsVVIN2PJMVj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598294165588,"user_tz":-120,"elapsed":604,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"6592ea5f-c01d-4946-e193-d2e5b0856a10"},"source":["## Remove last 24 hours as well as the part of test set not being used for main results\n","taxidemand_ts = taxidemand_ts.iloc[0:-192]\n","taxidemand_ts.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(8568,)"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"YoPamCvBYEso","colab_type":"code","colab":{}},"source":["# export the preprocessed data for plotting in R\n","taxidemand_ts.to_csv('/gdrive/My Drive/Colab Notebooks/traffic_1yr_plot.csv', index=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7R7xnarkTo_Y","colab_type":"code","colab":{}},"source":["## Set paramaters\n","data = taxidemand_ts.copy()\n","input_lags = 60 ## number of lags to be used for input. should be 2,5 times the seasonal period \n","output_lags = 24 ## number of future oberservations to be forecasted\n","n_test = 24 ## size of test set "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nho3_ThCTpDr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1598294170673,"user_tz":-120,"elapsed":597,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"5fecfdbd-9d87-49d2-bfe4-4cd06065b83c"},"source":["## Split data in train and test set\n","train = data[0:-n_test]\n","test = data[-n_test:]\n","print(train.shape)\n","print(test.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(8544,)\n","(24,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Pbs7Q3HkUnfZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598294173956,"user_tz":-120,"elapsed":774,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"c259090a-7d72-4621-dc4f-442a21c98378"},"source":["## Create dataframe with the correct dimensions. Each row represents the past 54 observations and the 24 future observations\n","df = pd.DataFrame()\n","n_train = len(train)\n","\n","## create inputs lags\n","for i in range(input_lags,0,-1):\n","    df['t-' + str(i)] = train.shift(i)\n","\n","## create output lags\n","for j in range(0,output_lags,1):\n","    df['t+' + str(j)] = train.shift(-j)\n","\n","## remove the first input_lags rows and last output_lags rows   \n","df = df[input_lags:(n_train-output_lags+1)]  \n","\n","print(df.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(8461, 84)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NQqdNzZ1Un3E","colab_type":"code","colab":{}},"source":["## Split train into features X and targets Y\n","X_train = df.iloc[:,:input_lags] \n","y_train = df.iloc[:,input_lags:]\n","\n","## To create the test features X_test we cannot use any of the test set, since that includes the data held out\n","# for testing. We therefor use the last input_lags number of observations in the training set. These are however\n","# split between the targets and features and requires a combination of the two. (output_lags) from the targets \n","# and (input_lags - output_lags) from the features\n","X_test = X_train.iloc[len(X_train) - 1,:][output_lags:] ## First get the last (input_lags - output_lags) from the features \n","X_test = X_test.append(y_train.iloc[len(y_train) - 1,:]) ## Second, add the last (output_lags) from the targets"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xhWQdK0yVJq0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1598294177920,"user_tz":-120,"elapsed":723,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"32da4a89-4091-4e41-a262-b9d92d48768b"},"source":["## Remodel as numpy arrays and reshape\n","X_train_multi = X_train.values ## should be (n - input_lags - outputlags - n_test + 1) x (input_lags)\n","y_train_multi = y_train.values ## should be (n - input_lags - outputlags - n_test + 1) x (output_lags)\n","X_test_multi = X_test.values.reshape(1,input_lags) ## should be (1) x (input_lags) \n","y_test_multi = test.values.reshape(1,n_test) ## should be (1) x (n_test)\n","\n","print(\"X_train_multi: \" + \"type: \" + str(type(X_train_multi)) + \"\\tshape: \" + str(X_train_multi.shape))\n","print(\"y_train_multi: \" + \"type: \" + str(type(y_train_multi)) + \"\\tshape: \" + str(y_train_multi.shape))\n","print(\"X_test_multi: \" + \"type: \" + str(type(X_test_multi)) + \"\\tshape: \" + str(X_test_multi.shape))\n","print(\"y_test_multi: \" + \"type: \" + str(type(y_test_multi)) + \"\\tshape: \" + str(y_test_multi.shape))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["X_train_multi: type: <class 'numpy.ndarray'>\tshape: (8461, 60)\n","y_train_multi: type: <class 'numpy.ndarray'>\tshape: (8461, 24)\n","X_test_multi: type: <class 'numpy.ndarray'>\tshape: (1, 60)\n","y_test_multi: type: <class 'numpy.ndarray'>\tshape: (1, 24)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ugerdqw5Un6N","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lJQCX216UOJJ","colab_type":"text"},"source":["$\\textbf{General motivation for XG boosting}:$\n","One advantages of the XGBoosting algorithm is that it comes with the built in option to include regularization which is why it is also called a regularized boosting sometimes.\n","It also comes with a built in cross validation option and it provides plenty of flexiblities for parameter tuning. XGboosting makes splits up to the specified \"max_depth\" parameter and then prunes the trees backwards.\n","The iterative nature of this algorithm is also an advantage: one can build a new model based on the specification of the previous iteration, which has been implemented during the fine tuning of parameters in this case."]},{"cell_type":"markdown","metadata":{"id":"pgGZuED8UOJJ","colab_type":"text"},"source":["$\\textbf{General setup of the algorithm}:$ As far as general parameters go, the booster \"gbtree\" has been used here, ie. I have been using tree based models in each iteration instead of a linear model, which is rarely used. I have started out with a number of estimators of 1,000 and then I have fine tuned the following parameters after try 2: max_depth and min_child_weight (gsearch1), reg_alpha (gsearch2), gamma (gsearch3), subsample and colsample_bytree (gsearch4), reg_lambda (gsearch5).  \n","I have used a feature importance plot of the XGBClassfier model to select the most important features to include. I have included the top 10 features out of the 24 features provided from try 3 onwards.\n","The fine tuned parameters have the following influence on the xg boosting algorithm:  \n","  \n","$\\textit{max_depth:}$ specifies the max depth of a tree and can be used to control overfitting as higher depth will allow the model to learn relations very specific to a particular sample   \n","$\\textit{min_child_weight:}$ this sets the minimum sum of weights of all observations required in a child. Higher values prevent the model from learning too specific relations.  \n","$\\textit{reg_alpha:}$ L1 regularization term. Can be used in case of high dimensionality to make the algorithm run faster. Can be a solution to overfitting in case of a relatively small dataset.  \n","$\\textit{gamma:}$ sets the minimum loss function required to make a split.  \n","$\\textit{subsample:}$ sets the fraction of observations to be random samples of each tree. lower values prevent overfitting but small too small values might lead to underfitting.  \n","$\\textit{colsample_bytree:}$ fraction of columns to be random samples of each tree.  \n","$\\textit{reg_lambda:}$ L2 regularization term. can be a solution to overfitting in case of a relatively small dataset. Can be explored to reduce overfitting."]},{"cell_type":"markdown","metadata":{"id":"pfln67RVUOJK","colab_type":"text"},"source":["## XG (Extreme Gradient) boosting "]},{"cell_type":"markdown","metadata":{"id":"Z6gd6B5qUOJL","colab_type":"text"},"source":["## Gridsearch CV"]},{"cell_type":"markdown","metadata":{"id":"OhUpkFKNZF3M","colab_type":"text"},"source":["**Blogpost for XGB Hyperparameter tuning:**\n","\n","https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/"]},{"cell_type":"markdown","metadata":{"id":"Ba5iRhU3dtF3","colab_type":"text"},"source":["**Full grid:**\n","\n","xgbreg_cv = GridSearchCV(estimator = xgb_model, param_grid = {\"colsample_bytree\":[0.6,0.8,1.0], 'subsample':[0.8,1.0],\"min_child_weight\":[1.0,1.2], 'learning_rate': [0.1,0.05,0.01]\n",", 'max_depth': [5,8,10], 'n_estimators': [500,1000], 'lambda': [0.7,0.8,1], 'alpha':[0.7,0.8,1.0]}, verbose=1, cv = inner_loop, n_jobs=3)"]},{"cell_type":"markdown","metadata":{"id":"BQ1tbRdyZtPk","colab_type":"text"},"source":["**Gridsearch CV for the Multioutput XGB model**"]},{"cell_type":"code","metadata":{"id":"L6I6MhOTZsLW","colab_type":"code","colab":{}},"source":["inner_splits = 3\n","inner_loop = TimeSeriesSplit(n_splits = inner_splits).split(X_train_multi,y_train_multi)\n","\n","# lambda: l2(ridge) regularization term on weights, alpha: l1(lasso) regularization term on weights\n","# njobs: parallel processing -> speeds up the process a lot (assumption: quad core CPU -> n_jobs = 4)\n","# nthread set to -1 uses all the cores available in the system\n","xgb_model_multi = MultiOutputRegressor(xgb.XGBRegressor(objective = \"reg:squarederror\", booster='gbtree', nthread=-1))\n","xgbreg_cv_multi = GridSearchCV(estimator = xgb_model_multi, param_grid = {\"estimator__colsample_bytree\":[0.8,1.0], 'estimator__subsample':[0.8],\"estimator__min_child_weight\":[1,3,5], 'estimator__learning_rate': [0.1,0.05,0.01]\n",", 'estimator__max_depth': [5,8,10], 'estimator__n_estimators': [500,1000], 'estimator__lambda': [0.7,1.0], 'estimator__alpha':[0.7,1.0]}, verbose=1, cv = inner_loop, n_jobs=4)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0hf2laf1eaEu","colab_type":"text"},"source":["Slightly reduced grid"]},{"cell_type":"code","metadata":{"id":"lBRcRmnuecu2","colab_type":"code","colab":{}},"source":["inner_splits = 3\n","inner_loop = TimeSeriesSplit(n_splits = inner_splits).split(X_train_multi,y_train_multi)\n","\n","# lambda: l2(ridge) regularization term on weights, alpha: l1(lasso) regularization term on weights\n","# njobs: parallel processing -> speeds up the process a lot (assumption: quad core CPU -> n_jobs = 4)\n","# nthread set to -1 uses all the cores available in the system\n","xgb_model_multi = MultiOutputRegressor(xgb.XGBRegressor(objective = \"reg:squarederror\", booster='gbtree', nthread=-1))\n","xgbreg_cv_multi = GridSearchCV(estimator = xgb_model_multi, param_grid = {\"estimator__colsample_bytree\":[0.8,1.0], 'estimator__subsample':[0.8],\"estimator__min_child_weight\":[3,5], 'estimator__learning_rate': [0.1,0.05,0.01]\n",", 'estimator__max_depth': [5,8], 'estimator__n_estimators': [500], 'estimator__lambda': [0.7,1.0], 'estimator__alpha':[0.7,1.0]}, verbose=1, cv = inner_loop, n_jobs=4)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vc7-PKNtaBVA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":538},"executionInfo":{"status":"ok","timestamp":1594990650355,"user_tz":-120,"elapsed":6159194,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"b78aad1c-3bfe-4958-d671-f31471984e5f"},"source":["xgbreg_cv_multi.fit(X_train_multi,y_train_multi)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Fitting 3 folds for each of 96 candidates, totalling 288 fits\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n","[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed: 13.3min\n","[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed: 66.3min\n","[Parallel(n_jobs=4)]: Done 288 out of 288 | elapsed: 102.1min finished\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["GridSearchCV(cv=<generator object TimeSeriesSplit.split at 0x7fa907727150>,\n","             error_score=nan,\n","             estimator=MultiOutputRegressor(estimator=XGBRegressor(base_score=0.5,\n","                                                                   booster='gbtree',\n","                                                                   colsample_bylevel=1,\n","                                                                   colsample_bynode=1,\n","                                                                   colsample_bytree=1,\n","                                                                   gamma=0,\n","                                                                   importance_type='gain',\n","                                                                   learning_rate=0.1,\n","                                                                   max_delta_step=0,\n","                                                                   max_depth=3,\n","                                                                   min_child_weight=1,\n","                                                                   missing=None,\n","                                                                   n_estimat...\n","             param_grid={'estimator__alpha': [0.7, 1.0],\n","                         'estimator__colsample_bytree': [0.8, 1.0],\n","                         'estimator__lambda': [0.7, 1.0],\n","                         'estimator__learning_rate': [0.1, 0.05, 0.01],\n","                         'estimator__max_depth': [5, 8],\n","                         'estimator__min_child_weight': [3, 5],\n","                         'estimator__n_estimators': [500],\n","                         'estimator__subsample': [0.8]},\n","             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n","             scoring=None, verbose=1)"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"fw4hSv2CaBcO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":156},"executionInfo":{"status":"ok","timestamp":1594991827658,"user_tz":-120,"elapsed":650,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"b9cc5de4-33de-4c4c-a5cc-ff65b324bdfc"},"source":["# obtaining the best hyperparameter values from the gridsearch cv\n","xgbreg_cv_multi.best_params_"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'estimator__alpha': 0.7,\n"," 'estimator__colsample_bytree': 0.8,\n"," 'estimator__lambda': 0.7,\n"," 'estimator__learning_rate': 0.05,\n"," 'estimator__max_depth': 5,\n"," 'estimator__min_child_weight': 5,\n"," 'estimator__n_estimators': 500,\n"," 'estimator__subsample': 0.8}"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"markdown","metadata":{"id":"wkMGlECaoHJx","colab_type":"text"},"source":["#LightGBM (Gradient Boosting)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"eYzGHCojvx2C","colab_type":"text"},"source":["https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMRegressor.html\n","\n","lightgbm parameters:\n","\n","https://lightgbm.readthedocs.io/en/latest/Parameters.html\n"]},{"cell_type":"markdown","metadata":{"id":"TCyt3sR2ojS4","colab_type":"text"},"source":["\n","Gridsearch CV \n"]},{"cell_type":"markdown","metadata":{"id":"qTY5nICwBAHy","colab_type":"text"},"source":["New Grid tailor made for LGBM"]},{"cell_type":"code","metadata":{"id":"OGKOY1QlA_LI","colab_type":"code","colab":{}},"source":["# LGBM specific new grid\n","\n","inner_splits = 3\n","inner_loop = TimeSeriesSplit(n_splits = inner_splits).split(X_train_multi,y_train_multi)\n","\n","# lambda: l2(ridge) regularization term on weights, alpha: l1(lasso) regularization term on weights \n","# njobs: parallel processing -> speeds up the process a lot (assumption: quad core CPU -> n_jobs = 4)\n","# nthread set to -1 uses all the cores available in the system\n","\n","# num_leaves: important parameter that controls the complexity of the tree model\n","# min_data_in_leaf: another important parameter to avoid overfitting of the leaf-wise tree algorithm. small -> overfitting\n","# This value is affected by the number of training sets and num_leaves. \n","# Setting this parameter larger can avoid growing too deep trees, but also avoid underfittinng\n","\n","# setting up the model with baseline parameters\n","lgbm_model_multi_new = MultiOutputRegressor(LGBMRegressor(boosting_type = \"gbdt\", objective = \"root_mean_squared_error\", n_jobs=-1))\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1PocRv6rLcpy","colab_type":"code","colab":{}},"source":["lgbm_cv_multi_new = GridSearchCV(estimator = lgbm_model_multi_new, param_grid = {\"estimator__num_leaves\":[30,40], \"estimator__min_child_samples\":[20,30], \"estimator__colsample_bytree\":[0.8,1.0],'estimator__subsample':[1.0],\"estimator__min_child_weight\":[0.01,3], 'estimator__learning_rate': [0.1,0.01],'estimator__max_depth': [5,8], 'estimator__n_estimators': [250,500], 'estimator__reg_lambda': [0.0,0.7], 'estimator__reg_alpha':[0.0,0.7]}, verbose=1, cv = inner_loop, n_jobs=-1, scoring=\"neg_root_mean_squared_error\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G5-n_yS-NvNW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":561},"executionInfo":{"status":"ok","timestamp":1598330746856,"user_tz":-120,"elapsed":36330152,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"643547f3-89b1-4c7e-c2b9-457a20d3a6e6"},"source":["lgbm_cv_multi_new.fit(X_train_multi,y_train_multi) "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Fitting 3 folds for each of 512 candidates, totalling 1536 fits\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  8.6min\n","[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 38.6min\n","[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 123.8min\n","[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed: 275.8min\n","[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed: 439.9min\n","[Parallel(n_jobs=-1)]: Done 1536 out of 1536 | elapsed: 605.1min finished\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["GridSearchCV(cv=<generator object TimeSeriesSplit.split at 0x7f08a603f888>,\n","             error_score=nan,\n","             estimator=MultiOutputRegressor(estimator=LGBMRegressor(boosting_type='gbdt',\n","                                                                    class_weight=None,\n","                                                                    colsample_bytree=1.0,\n","                                                                    importance_type='split',\n","                                                                    learning_rate=0.1,\n","                                                                    max_depth=-1,\n","                                                                    min_child_samples=20,\n","                                                                    min_child_weight=0.001,\n","                                                                    min_split_gain=0.0,\n","                                                                    n_estimators=100,\n","                                                                    n_jobs=-1,\n","                                                                    num...\n","                         'estimator__max_depth': [5, 8],\n","                         'estimator__min_child_samples': [20, 30],\n","                         'estimator__min_child_weight': [0.01, 3],\n","                         'estimator__n_estimators': [250, 500],\n","                         'estimator__num_leaves': [30, 40],\n","                         'estimator__reg_alpha': [0.0, 0.7],\n","                         'estimator__reg_lambda': [0.0, 0.7],\n","                         'estimator__subsample': [1.0]},\n","             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n","             scoring=None, verbose=1)"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"T8Q-3uVcNyFD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":187},"executionInfo":{"status":"ok","timestamp":1598330746860,"user_tz":-120,"elapsed":36290270,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"d6375571-f0f7-40e4-a221-0a822d4360fb"},"source":["# obtaining the best hyperparameter values from the gridsearch cv\n","lgbm_cv_multi_new.best_params_"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'estimator__colsample_bytree': 0.8,\n"," 'estimator__learning_rate': 0.1,\n"," 'estimator__max_depth': 8,\n"," 'estimator__min_child_samples': 30,\n"," 'estimator__min_child_weight': 0.01,\n"," 'estimator__n_estimators': 250,\n"," 'estimator__num_leaves': 30,\n"," 'estimator__reg_alpha': 0.0,\n"," 'estimator__reg_lambda': 0.7,\n"," 'estimator__subsample': 1.0}"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"zDetquI3NyCb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598332227813,"user_tz":-120,"elapsed":565,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"fc5962a8-f370-4f35-e2ee-7ddc221f23ff"},"source":["lgbm_cv_multi_new.best_score_"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9023750407104661"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"2KXZr7NuUOJe","colab_type":"text"},"source":["## Fitting the optimal model"]},{"cell_type":"markdown","metadata":{"id":"FWpKaFr0wzK2","colab_type":"text"},"source":["# XGBoosting Optimal model"]},{"cell_type":"code","metadata":{"id":"6uFoVlb0UOJf","colab_type":"code","colab":{}},"source":["# learning rate is the step size shrinkage used to prevent overfitting. Range is [0,1]\n","# lambda: default = 1,  L2 regularization term on weights (analogous to Ridge regression)\n","# this used to handle the regularization part of XGBoost. Though many data scientists don’t use it often, \n","# it should be explored to reduce overfitting.\n","# max_depth is also used to control overfitting as higher depth will allow model to learn relations very specific to a particular sample\n","\n","# alpha: L1 regularization on leaf weights. A large value leads to more regularization\n","# In order to build more robust models, it is common to do a k-fold cross validation where \n","# all the entries in the original training dataset are used for both training as well as validation\n","# XGBoost supports k-fold cross validation via the cv() method. All you have to do is specify the nfolds parameter, \n","# which is the number of cross validation sets you want to build.\n","\n","\n","xgb_reg_opt=xgb.XGBRegressor(random_state=1,learning_rate=0.05, objective = \"reg:squarederror\", n_estimators =500, colsample_bytree = 0.8, max_depth = 5, subsample= 0.8, min_child_weight =5, reg_lambda = 0.7, alpha= 0.7, eval_metric = \"rmse\")\n","\n","## Fitting a single output regressor xgb model\n","#xgb_reg_opt.fit(X_train, y_train)\n","\n","# Fitting a Multioutputregressor xgb model to obtain multioutput forecasts\n","\n","multioutputregressor_fit = MultiOutputRegressor(xgb_reg_opt).fit(X_train_multi, y_train_multi)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z-NPvWV-UOJn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":208},"executionInfo":{"status":"ok","timestamp":1594658072528,"user_tz":-120,"elapsed":896,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"ee001c04-5209-4c73-837e-e2208e21a665"},"source":["# (lag) feature importance scores\n","xgb_reg_opt.feature_importances_"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.00218971, 0.00434436, 0.00916981, 0.00202504, 0.00149078,\n","       0.00168853, 0.00073392, 0.0034906 , 0.00096166, 0.00130496,\n","       0.00144312, 0.00224894, 0.0008032 , 0.00142685, 0.00070412,\n","       0.00225331, 0.00078325, 0.00066303, 0.00090281, 0.00085732,\n","       0.00087486, 0.00072116, 0.00092707, 0.00064558, 0.00161666,\n","       0.00651186, 0.002436  , 0.00116427, 0.00075428, 0.00072861,\n","       0.05196435, 0.05025709, 0.03885129, 0.01461791, 0.00254124,\n","       0.00161706, 0.00094993, 0.00071457, 0.01119858, 0.0036468 ,\n","       0.00103879, 0.00112749, 0.0008306 , 0.00107581, 0.00689208,\n","       0.00202745, 0.0006693 , 0.0030678 , 0.07589586, 0.11545025,\n","       0.00691677, 0.00203558, 0.00195733, 0.54879045], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":65}]},{"cell_type":"markdown","metadata":{"id":"hlCnunULw3cd","colab_type":"text"},"source":["#LightGBM optimal model\n"]},{"cell_type":"code","metadata":{"id":"VOzGeyT2OOYw","colab_type":"code","colab":{}},"source":["# best model\n","lgbm_reg_opt_new = LGBMRegressor(random_state=1,learning_rate=0.1, objective = \"root_mean_squared_error\", n_estimators =500, colsample_bytree = 0.8, max_depth = 8, subsample= 1.0, num_leaves=30, min_child_samples=20, min_child_weight =3, reg_lambda = 0.7, reg_alpha= 0.0, eval_metric = \"rmse\",boosting_type=\"gbdt\")\n","\n","lgbm_moreg_fit_new = MultiOutputRegressor(lgbm_reg_opt_new).fit(X_train_multi, y_train_multi)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nzNAKHc9xn4-","colab_type":"text"},"source":["#Quantile Regression loss function for Prediction intervals"]},{"cell_type":"markdown","metadata":{"id":"Bid1JRDvvV2P","colab_type":"text"},"source":["Way 1 (lightgbm)\n"]},{"cell_type":"code","metadata":{"id":"HtOwzlU8TzDC","colab_type":"code","colab":{}},"source":["#### 95% Prediction Intervals - Upper bound ####\n","# upper bound \n","alpha = 0.975\n","\n","\n","# Gridsearch CV for alpha = 0.975 and a quantile loss function\n","\n","inner_splits = 3\n","inner_loop = TimeSeriesSplit(n_splits = inner_splits).split(X_train_multi,y_train_multi)\n","\n","# lambda: l2(ridge) regularization term on weights, alpha: l1(lasso) regularization term on weights\n","# njobs: parallel processing -> speeds up the process a lot (assumption: quad core CPU -> n_jobs = 4)\n","# nthread set to -1 uses all the cores available in the system\n","lgbm_multi_pi_upper = MultiOutputRegressor(LGBMRegressor(boosting_type = \"gbdt\", objective = \"quantile\", n_jobs=-1, alpha = alpha))\n","lgbm_multi_cv_upper = GridSearchCV(estimator = lgbm_multi_pi_upper, param_grid = {\"estimator__colsample_bytree\":[0.8,1.0],'estimator__subsample':[1.0],\"estimator__min_child_weight\":[3,5], 'estimator__learning_rate': [0.1,0.01,0.001]\n",", 'estimator__max_depth': [5,8], 'estimator__n_estimators': [500], 'estimator__reg_lambda': [0.7,1.0], 'estimator__reg_alpha':[0.7,1.0]}, verbose=1, cv = inner_loop, n_jobs=-1)\n","\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2J6BO77r3Jti","colab_type":"code","colab":{}},"source":["lgbm_multi_cv_upper.fit(X_train_multi,y_train_multi)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kSiwkczW5n3f","colab_type":"code","colab":{}},"source":["# obtaining the best hyperparameter values from the gridsearch cv (upper bound)\n","lgbm_multi_cv_upper.best_params_"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NHpFsBEFm7Lz","colab_type":"text"},"source":["**Optimal parameters upper bound GSCV:**\n","\n","{'estimator__colsample_bytree': 0.8,\n"," 'estimator__learning_rate': 0.1,\n"," 'estimator__max_depth': 5,\n"," 'estimator__min_child_weight': 3,\n"," 'estimator__n_estimators': 500,\n"," 'estimator__reg_alpha': 0.7,\n"," 'estimator__reg_lambda': 1.0,\n"," 'estimator__subsample': 0.8}\n"," "]},{"cell_type":"code","metadata":{"id":"sOZcQymU2b2W","colab_type":"code","colab":{}},"source":["# Fitting the optimal PI model for the upper PI bound (alpha = 0.975 & quantile loss)\n","\n","alpha = 0.975\n","\n","lgbm_reg_pi=LGBMRegressor(random_state=1,learning_rate=0.1, objective = \"quantile\", n_estimators =500, colsample_bytree = 0.8, max_depth = 5, subsample= 1.0, min_child_weight =3, reg_lambda = 1.0, reg_alpha= 0.7, alpha=alpha, eval_metric = \"rmse\")\n","\n","\n","lgbm_reg_fit_upper = MultiOutputRegressor(lgbm_reg_pi).fit(X_train_multi, y_train_multi)\n","\n","# Make the prediction on the meshed x-axis\n","y_upper = lgbm_reg_fit_upper.predict(X_test_multi)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lejkIfGa3ez0","colab_type":"code","colab":{}},"source":["#### 95% Prediction Intervals - Lower bound ####\n","\n","alpha = 0.025\n","\n","# Gridsearch CV for alpha = 0.025 and a quantile loss function\n","\n","inner_splits = 3\n","inner_loop = TimeSeriesSplit(n_splits = inner_splits).split(X_train_multi,y_train_multi)\n","\n","# lambda: l2(ridge) regularization term on weights, alpha: l1(lasso) regularization term on weights\n","# njobs: parallel processing -> speeds up the process a lot (assumption: quad core CPU -> n_jobs = 4)\n","# nthread set to -1 uses all the cores available in the system\n","lgbm_multi_pi_lower = MultiOutputRegressor(LGBMRegressor(boosting_type = \"gbdt\", objective = \"quantile\", n_jobs=-1, alpha = alpha))\n","lgbm_multi_cv_lower = GridSearchCV(estimator = lgbm_multi_pi_lower, param_grid = {\"estimator__colsample_bytree\":[0.8,1.0],'estimator__subsample':[1.0],\"estimator__min_child_weight\":[3,5], 'estimator__learning_rate': [0.1,0.01,0.001]\n",", 'estimator__max_depth': [5,8], 'estimator__n_estimators': [500], 'estimator__reg_lambda': [0.7,1.0], 'estimator__reg_alpha':[0.7,1.0]}, verbose=1, cv = inner_loop, n_jobs=-1)\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1vTxdSPJ6uMd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":521},"executionInfo":{"status":"ok","timestamp":1595510339176,"user_tz":-120,"elapsed":1385704,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"5e137d95-618d-4c52-897b-c1ec73f5b0b9"},"source":["lgbm_multi_cv_lower.fit(X_train_multi,y_train_multi)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Fitting 3 folds for each of 96 candidates, totalling 288 fits\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n","[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  3.1min\n","[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed: 14.7min\n","[Parallel(n_jobs=4)]: Done 288 out of 288 | elapsed: 22.9min finished\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["GridSearchCV(cv=<generator object TimeSeriesSplit.split at 0x7fc9e695ed00>,\n","             error_score=nan,\n","             estimator=MultiOutputRegressor(estimator=LGBMRegressor(alpha=0.025,\n","                                                                    boosting_type='gbdt',\n","                                                                    class_weight=None,\n","                                                                    colsample_bytree=1.0,\n","                                                                    importance_type='split',\n","                                                                    learning_rate=0.1,\n","                                                                    max_depth=-1,\n","                                                                    min_child_samples=20,\n","                                                                    min_child_weight=0.001,\n","                                                                    min_split_gain=0.0,\n","                                                                    n_estimators=100,\n","                                                                    n...\n","             param_grid={'estimator__colsample_bytree': [0.8, 1.0],\n","                         'estimator__learning_rate': [0.1, 0.05, 0.01],\n","                         'estimator__max_depth': [5, 8],\n","                         'estimator__min_child_weight': [3, 5],\n","                         'estimator__n_estimators': [500],\n","                         'estimator__reg_alpha': [0.7, 1.0],\n","                         'estimator__reg_lambda': [0.7, 1.0],\n","                         'estimator__subsample': [0.8]},\n","             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n","             scoring=None, verbose=1)"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"q4OR5sP-5yt4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":156},"executionInfo":{"status":"ok","timestamp":1595510374135,"user_tz":-120,"elapsed":683,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"86cb8de6-54ce-4085-e2cd-d99391c9b839"},"source":["# obtaining the best hyperparameter values from the gridsearch cv (lower bound)\n","lgbm_multi_cv_lower.best_params_"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'estimator__colsample_bytree': 0.8,\n"," 'estimator__learning_rate': 0.1,\n"," 'estimator__max_depth': 8,\n"," 'estimator__min_child_weight': 3,\n"," 'estimator__n_estimators': 500,\n"," 'estimator__reg_alpha': 0.7,\n"," 'estimator__reg_lambda': 1.0,\n"," 'estimator__subsample': 0.8}"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"BDt107nAslyJ","colab_type":"text"},"source":["**Optimal hyperparams (lower bound) GSCV:**\n","\n","{'estimator__colsample_bytree': 0.8,\n"," 'estimator__learning_rate': 0.1,\n"," 'estimator__max_depth': 8,\n"," 'estimator__min_child_weight': 3,\n"," 'estimator__n_estimators': 500,\n"," 'estimator__reg_alpha': 0.7,\n"," 'estimator__reg_lambda': 1.0,\n"," 'estimator__subsample': 0.8}\n"," "]},{"cell_type":"code","metadata":{"id":"jzKgIjeE2MLm","colab_type":"code","colab":{}},"source":["# Fitting the optimal PI model for the lower PI bound (alpha = 0.025 & quantile loss)\n","\n","alpha = 0.025\n","\n","lgbm_reg_pi=LGBMRegressor(random_state=1,learning_rate=0.1, objective = \"quantile\", n_estimators =500, colsample_bytree = 0.8, max_depth = 8, subsample= 1.0, min_child_weight =3, reg_lambda = 1.0, reg_alpha= 0.7, alpha=alpha, eval_metric = \"rmse\")\n","\n","\n","lgbm_reg_fit_lower = MultiOutputRegressor(lgbm_reg_pi).fit(X_train_multi, y_train_multi)\n","\n","# Make the prediction on the meshed x-axis\n","y_lower = lgbm_reg_fit_lower.predict(X_test_multi)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vJKvfAVUvZTX","colab_type":"text"},"source":["Way 2"]},{"cell_type":"markdown","metadata":{"id":"Y-pedJZlvrz0","colab_type":"text"},"source":["https://scikit-learn.org/stable/auto_examples/ensemble/plot_gradient_boosting_quantile.html"]},{"cell_type":"markdown","metadata":{"id":"aMD_uVblvwSk","colab_type":"text"},"source":["https://towardsdatascience.com/regression-prediction-intervals-with-xgboost-428e0a018b"]},{"cell_type":"code","metadata":{"id":"Lp_w16S63Zvw","colab_type":"code","colab":{}},"source":["from functools import partial"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9tB1YkpJwUad","colab_type":"code","colab":{}},"source":["class XGBQuantile(xgb.XGBRegressor):\n","  def __init__(self,quant_alpha=0.95,quant_delta = 1.0,quant_thres=1.0,quant_var =1.0,base_score=0.5, booster='gbtree', colsample_bylevel=1,\n","                colsample_bytree=1, gamma=0, learning_rate=0.1, eval_metric = \"rmse\", max_delta_step=0,max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n","                n_jobs=1, nthread=None, objective='reg:linear', random_state=0,reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,silent=True, subsample=1):\n","    self.quant_alpha = quant_alpha\n","    self.quant_delta = quant_delta\n","    self.quant_thres = quant_thres\n","    self.quant_var = quant_var\n","    \n","    super().__init__(base_score=base_score, booster=booster, colsample_bylevel=colsample_bylevel,\n","       colsample_bytree=colsample_bytree, gamma=gamma, learning_rate=learning_rate, max_delta_step=max_delta_step,\n","       max_depth=max_depth, min_child_weight=min_child_weight, missing=missing, n_estimators=n_estimators,\n","       n_jobs= n_jobs, nthread=nthread, objective=objective, random_state=random_state,\n","       reg_alpha=reg_alpha, reg_lambda=reg_lambda, scale_pos_weight=scale_pos_weight, seed=seed,\n","       silent=silent, subsample=subsample)\n","    \n","    self.test = None\n","  \n","  def fit(self, X, y):\n","    super().set_params(objective=partial(XGBQuantile.quantile_loss,alpha = self.quant_alpha,delta = self.quant_delta,threshold = self.quant_thres,var = self.quant_var) )\n","    super().fit(X,y)\n","    return self\n","  \n","  def predict(self,X):\n","    return super().predict(X)\n","  \n","  def score(self, X, y):\n","    y_pred = super().predict(X)\n","    score = XGBQuantile.quantile_score(y, y_pred, self.quant_alpha)\n","    score = 1./score\n","    return score\n","      \n","  @staticmethod\n","  def quantile_loss(y_true,y_pred,alpha,delta,threshold,var):\n","    x = y_true - y_pred\n","    grad = (x<(alpha-1.0)*delta)*(1.0-alpha)-  ((x>=(alpha-1.0)*delta)& (x<alpha*delta) )*x/delta-alpha*(x>alpha*delta)\n","    hess = ((x>=(alpha-1.0)*delta)& (x<alpha*delta) )/delta \n"," \n","    grad = (np.abs(x)<threshold )*grad - (np.abs(x)>=threshold )*(2*np.random.randint(2, size=len(y_true)) -1.0)*var\n","    hess = (np.abs(x)<threshold )*hess + (np.abs(x)>=threshold )\n","    return grad, hess\n","  \n","  @staticmethod\n","  def original_quantile_loss(y_true,y_pred,alpha,delta):\n","    x = y_true - y_pred\n","    grad = (x<(alpha-1.0)*delta)*(1.0-alpha)-((x>=(alpha-1.0)*delta)& (x<alpha*delta) )*x/delta-alpha*(x>alpha*delta)\n","    hess = ((x>=(alpha-1.0)*delta)& (x<alpha*delta) )/delta \n","    return grad,hess\n","\n","  \n","  @staticmethod\n","  def quantile_score(y_true, y_pred, alpha):\n","    score = XGBQuantile.quantile_cost(x=y_true-y_pred,alpha=alpha)\n","    score = np.sum(score)\n","    return score\n","  \n","  @staticmethod\n","  def quantile_cost(x, alpha):\n","    return (alpha-1.0)*x*(x<0)+alpha*x*(x>=0)\n","  \n","  @staticmethod\n","  def get_split_gain(gradient,hessian,l=1):\n","    split_gain = list()\n","    for i in range(gradient.shape[0]):\n","      split_gain.append(np.sum(gradient[:i])/(np.sum(hessian[:i])+l)+np.sum(gradient[i:])/(np.sum(hessian[i:])+l)-np.sum(gradient)/(np.sum(hessian)+l) )\n","    \n","    return np.array(split_gain)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jcNkdfLJUOJ0","colab_type":"text"},"source":["## Obtaining predictions"]},{"cell_type":"markdown","metadata":{"id":"ik5AQRJ9XePJ","colab_type":"text"},"source":["**Multi-output model**"]},{"cell_type":"markdown","metadata":{"id":"Dy8oIJ8zzHeu","colab_type":"text"},"source":["XGBoosting"]},{"cell_type":"code","metadata":{"id":"xwkxs-NGXjaP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595252172761,"user_tz":-120,"elapsed":1269,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"7c89890c-ed06-497a-e6e5-27b4c71aa6f6"},"source":["# running the retrained model on the test data\n","xgb_preds_multi = multioutputregressor_fit.predict(X_test_multi)\n","xgb_preds_multi.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1, 24)"]},"metadata":{"tags":[]},"execution_count":67}]},{"cell_type":"code","metadata":{"id":"GKO4VAScYvZD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594992047597,"user_tz":-120,"elapsed":659,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"c885a7d3-c8c6-4935-940e-a544269bffac"},"source":["# MSE\n","mse_xgbreg_multi = mean_squared_error(y_test_multi, xgb_preds_multi)\n","mse_xgbreg_multi"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["704699.0461237734"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"id":"fbzgzJ-2Y15_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594992049348,"user_tz":-120,"elapsed":606,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"a274005b-ccb8-4e64-c7b5-a724226fbacd"},"source":["# RMSE\n","sqrt(mse_xgbreg_multi)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["839.4635466318794"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"5Oi_cj0WY190","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594992052013,"user_tz":-120,"elapsed":580,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"3bb1abd3-37f0-41a4-be13-9dd13b892d4e"},"source":["# MAE\n","mean_absolute_error(y_test_multi, xgb_preds_multi)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["609.5590057373047"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"ni8_diV3ZDD_","colab_type":"code","colab":{}},"source":["# custom MAPE function\n","def mean_absolute_percentage_error(y_true, y_pred): \n","    \"\"\"Calculates MAPE given y_true and y_pred\"\"\"\n","    y_true, y_pred = np.array(y_true), np.array(y_pred)\n","    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n","\n","y_true = y_test_multi\n","y_pred = xgb_preds_multi\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R5ckUgXFZPcY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594992057548,"user_tz":-120,"elapsed":618,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"3b16d4ba-1dc2-421b-9cc2-82dd7db7d1ee"},"source":["# MAPE\n","mean_absolute_percentage_error(y_true,y_pred)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["7.614215276811718"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"markdown","metadata":{"id":"jS_xcBTOzKFS","colab_type":"text"},"source":["LIGHTGBM"]},{"cell_type":"code","metadata":{"id":"ZNKPP8JwOZF3","colab_type":"code","colab":{}},"source":["lgbm_preds_new = lgbm_moreg_fit_new.predict(X_test_multi)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ySezbidoPHwh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598332983710,"user_tz":-120,"elapsed":538,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"701a77c5-e52a-4490-a5b4-904b1d4ad925"},"source":["# MSE\n","mse_lgbm_new = mean_squared_error(y_test_multi, lgbm_preds_new)\n","mse_lgbm_new"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["652952.8460385905"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"id":"cUoVb4uUPH0A","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598332985151,"user_tz":-120,"elapsed":547,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"0c429023-c24b-43d5-c0bd-928372813046"},"source":["# RMSE\n","sqrt(mse_lgbm_new)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["808.0549771139279"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"8OR5GAcEu2Si","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598332990736,"user_tz":-120,"elapsed":577,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"5a57cba0-4d03-47d5-fb2b-c9e8817f7849"},"source":["# MAE\n","mean_absolute_error(y_test_multi, lgbm_preds_new)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["611.9593419973806"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"PJcqk8YOu2PB","colab_type":"code","colab":{}},"source":["# custom MAPE function\n","def mean_absolute_percentage_error(y_true, y_pred): \n","    \"\"\"Calculates MAPE given y_true and y_pred\"\"\"\n","    y_true, y_pred = np.array(y_true), np.array(y_pred)\n","    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n","\n","y_true = y_test_multi\n","y_pred = lgbm_preds_new"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xayWWdvtvL_u","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1597656434973,"user_tz":-120,"elapsed":538,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"4410b511-213e-410a-b437-ac3e7b491bf0"},"source":["# MAPE\n","mean_absolute_percentage_error(y_true,y_pred)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["9.39391830158383"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"markdown","metadata":{"id":"Yq7NwZnUWyny","colab_type":"text"},"source":["**Exporting the Data as a CSV file:**\n"]},{"cell_type":"code","metadata":{"id":"clbQmMM-VrLL","colab_type":"code","colab":{}},"source":["\n","\n","# Creating a dataframe with GRU predictions and test data\n","LGBM_df = pd.DataFrame(np.transpose(lgbm_preds_multi))\n","\n","# adding a column with the test data\n","LGBM_df[\"PI upper bound\"] = np.transpose(y_upper)\n","LGBM_df[\"PI lower bound\"] = np.transpose(y_lower)\n","LGBM_df[\"Test data\"] = np.transpose(y_test_multi)\n","\n","\n","LGBM_df.columns = ['LGBM predictions', \"PI upper bound\", \"PI lower bound\", 'Test data']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SiueiZQqZvF0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":802},"executionInfo":{"status":"ok","timestamp":1597228113470,"user_tz":-120,"elapsed":1181,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"7a75a9a1-a6e6-4787-9b33-d8ac59b7c996"},"source":["LGBM_df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>LGBM predictions</th>\n","      <th>PI upper bound</th>\n","      <th>PI lower bound</th>\n","      <th>Test data</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10775.684187</td>\n","      <td>11989.102104</td>\n","      <td>10052.530400</td>\n","      <td>11284</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>8785.240102</td>\n","      <td>10255.177836</td>\n","      <td>6991.671354</td>\n","      <td>9431</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>7417.886066</td>\n","      <td>8736.246831</td>\n","      <td>4155.632162</td>\n","      <td>7524</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4760.588988</td>\n","      <td>6079.624763</td>\n","      <td>2193.597025</td>\n","      <td>5155</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>3079.153578</td>\n","      <td>4226.169554</td>\n","      <td>1730.670195</td>\n","      <td>3075</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2349.560298</td>\n","      <td>4917.127980</td>\n","      <td>2034.047477</td>\n","      <td>1790</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>4080.604715</td>\n","      <td>8291.035464</td>\n","      <td>3362.204861</td>\n","      <td>2571</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>6213.181292</td>\n","      <td>11857.649223</td>\n","      <td>4217.161542</td>\n","      <td>3975</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>8325.297125</td>\n","      <td>14743.700593</td>\n","      <td>6441.890914</td>\n","      <td>5945</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>9135.712462</td>\n","      <td>13749.349079</td>\n","      <td>8374.541383</td>\n","      <td>8115</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>10329.995873</td>\n","      <td>13421.766107</td>\n","      <td>9696.186442</td>\n","      <td>9430</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>10776.887206</td>\n","      <td>13719.276303</td>\n","      <td>9837.185809</td>\n","      <td>10589</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>12007.038879</td>\n","      <td>13818.234464</td>\n","      <td>10508.890650</td>\n","      <td>11434</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>12077.096580</td>\n","      <td>14321.780740</td>\n","      <td>11205.071642</td>\n","      <td>12003</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>12197.663182</td>\n","      <td>14547.323417</td>\n","      <td>11357.651073</td>\n","      <td>11607</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>12189.726669</td>\n","      <td>14763.177256</td>\n","      <td>11376.633704</td>\n","      <td>11612</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>12081.140169</td>\n","      <td>14350.543139</td>\n","      <td>11045.824071</td>\n","      <td>11254</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>12827.527050</td>\n","      <td>15154.851897</td>\n","      <td>11436.748550</td>\n","      <td>12367</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>13106.044611</td>\n","      <td>16531.576070</td>\n","      <td>12577.660930</td>\n","      <td>13028</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>12697.500898</td>\n","      <td>16684.157226</td>\n","      <td>11129.450100</td>\n","      <td>12649</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>11287.574838</td>\n","      <td>15685.105702</td>\n","      <td>10312.168082</td>\n","      <td>10736</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>10809.567242</td>\n","      <td>15023.252373</td>\n","      <td>9720.171288</td>\n","      <td>10975</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>11735.657511</td>\n","      <td>15182.775099</td>\n","      <td>9045.518445</td>\n","      <td>12467</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>11973.188690</td>\n","      <td>14334.097295</td>\n","      <td>7374.200768</td>\n","      <td>12054</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    LGBM predictions  PI upper bound  PI lower bound  Test data\n","0       10775.684187    11989.102104    10052.530400      11284\n","1        8785.240102    10255.177836     6991.671354       9431\n","2        7417.886066     8736.246831     4155.632162       7524\n","3        4760.588988     6079.624763     2193.597025       5155\n","4        3079.153578     4226.169554     1730.670195       3075\n","5        2349.560298     4917.127980     2034.047477       1790\n","6        4080.604715     8291.035464     3362.204861       2571\n","7        6213.181292    11857.649223     4217.161542       3975\n","8        8325.297125    14743.700593     6441.890914       5945\n","9        9135.712462    13749.349079     8374.541383       8115\n","10      10329.995873    13421.766107     9696.186442       9430\n","11      10776.887206    13719.276303     9837.185809      10589\n","12      12007.038879    13818.234464    10508.890650      11434\n","13      12077.096580    14321.780740    11205.071642      12003\n","14      12197.663182    14547.323417    11357.651073      11607\n","15      12189.726669    14763.177256    11376.633704      11612\n","16      12081.140169    14350.543139    11045.824071      11254\n","17      12827.527050    15154.851897    11436.748550      12367\n","18      13106.044611    16531.576070    12577.660930      13028\n","19      12697.500898    16684.157226    11129.450100      12649\n","20      11287.574838    15685.105702    10312.168082      10736\n","21      10809.567242    15023.252373     9720.171288      10975\n","22      11735.657511    15182.775099     9045.518445      12467\n","23      11973.188690    14334.097295     7374.200768      12054"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"code","metadata":{"id":"aJrhw2C1Z5IA","colab_type":"code","colab":{}},"source":["# saving the dataframe as a CSV file\n","LGBM_df.to_csv('/gdrive/My Drive/Colab Notebooks/LGBM_preds.csv', index=False)"],"execution_count":null,"outputs":[]}]}