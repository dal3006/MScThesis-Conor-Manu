{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"LGBM_emergency_dayofweek.ipynb","provenance":[{"file_id":"1VWyl_Nokyt_BxSz0hoBw8-VGfPbyE2-v","timestamp":1598519675990},{"file_id":"1uWw2wZyZ8yORKTYJ3fKRfEsKjYvuLcpa","timestamp":1598465352152},{"file_id":"1B3RwPaDkpiRYdoj7BB0XD4fa9lmK3xOk","timestamp":1596382012502}],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"y6YsUR3mUOEy","colab_type":"text"},"source":["# LGBM for the emergency demand predictions"]},{"cell_type":"markdown","metadata":{"id":"3d2qnLn3UOE1","colab_type":"text"},"source":["https://www.kaggle.com/robikscube/tutorial-time-series-forecasting-with-xgboost"]},{"cell_type":"markdown","metadata":{"id":"4jMJD4_iUOE4","colab_type":"text"},"source":["Importing libraries"]},{"cell_type":"code","metadata":{"id":"2KN6E8MKUOE7","colab_type":"code","colab":{}},"source":["# general routine set up:\n","\n","# ignore warnings\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","# get wd and change the wd plus import libraries\n","import os\n","os.getcwd()\n","#os.chdir(\"/Users/Manu/Dropbox/CBS MSc Thesis Research Folder/DATA & Code/Model Specific Notebooks\")\n","\n","\n","# standard\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt \n","%matplotlib inline\n","from math import sqrt\n","import pickle\n","\n","# ML\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.model_selection import TimeSeriesSplit\n","from sklearn.model_selection import train_test_split\n","import xgboost as xgb\n","from xgboost import plot_importance, plot_tree\n","from sklearn.metrics import mean_squared_error, mean_absolute_error\n","from sklearn.multioutput import MultiOutputRegressor\n","import tensorflow.keras.backend as K\n","from lightgbm import LGBMRegressor"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JDuBnHiZUOFN","colab_type":"text"},"source":["Loading the data"]},{"cell_type":"code","metadata":{"id":"aIizwmU9XRQK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600100610424,"user_tz":-120,"elapsed":30413,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"135934cc-1552-485e-d138-c5f8cd132825"},"source":["# this allows for accessing files stored in your google drive using the path \"/gdrive/\"\n","# mounting google drive locally:\n","\n","from google.colab import drive\n","drive.mount('/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9R3DJqolXY_e","colab_type":"code","colab":{}},"source":["#loading the hourly traffic data (1 year of data; June 2018 to June 2019)\n","filename = \"/gdrive/My Drive/Colab Notebooks/emergency_dispatches_bronx_H\"\n","infile = open(filename,'rb')\n","emergency_ts = pickle.load(infile)\n","infile.close()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z-AofGAaUOFY","colab_type":"text"},"source":["Preprocessing: already done\n"]},{"cell_type":"markdown","metadata":{"id":"exVAFiNZUOF4","colab_type":"text"},"source":["Time Series data must be re-framed as a supervised learning dataset before we can start using machine learning algorithms.  \n","There is no concept of input and output features in time series. Instead, we must choose the variable to be predicted and use feature engineering to construct all of the inputs that will be used to make predictions for future time steps."]},{"cell_type":"markdown","metadata":{"id":"9atRO7l0UOF7","colab_type":"text"},"source":["## Feature Engineering for Times Series"]},{"cell_type":"markdown","metadata":{"id":"ameUwQssUOF8","colab_type":"text"},"source":["[feature_eng_ts.png](attachment:feature_eng_ts.png)"]},{"cell_type":"markdown","metadata":{"id":"Wu-0lspKUOF9","colab_type":"text"},"source":["In this tutorial, we will look at three classes of features that we can create from our time series dataset:\n","\n","    Date Time Features: these are components of the time step itself for each observation.\n","    Lag Features: these are values at prior time steps.\n","    Window Features: these are a summary of values over a fixed window of prior time steps.\n"]},{"cell_type":"markdown","metadata":{"id":"sYbH0vQDUOF_","colab_type":"text"},"source":["Lag features are the classical way that time series forecasting problems are transformed into supervised learning problems."]},{"cell_type":"markdown","metadata":{"id":"kBbg_jTeUOGA","colab_type":"text"},"source":["The goal of feature engineering is to provide strong and ideally simple relationships between new input features and the output feature for the supervised learning algorithm to model."]},{"cell_type":"markdown","metadata":{"id":"wc-6qP1mFq8i","colab_type":"text"},"source":["### Preprocessing for monday the 16"]},{"cell_type":"code","metadata":{"id":"yK6ejFwNbnYb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600100669502,"user_tz":-120,"elapsed":1242,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"cef283b8-c6ac-4818-91d1-b293289d432e"},"source":["## Remove last 15 days of data since they are either erroneous or part of the test set to the robustness checks\n","emergency_ts_mon = emergency_ts.iloc[0:-360]\n","emergency_ts_mon.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(8400,)"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"-gTDE4GqFq8k","colab_type":"code","colab":{}},"source":["## Set paramaters\n","input_lags = 60 # 2 and a half times the seasonal period\n","output_lags = 24 # we predict 24 hours ahead\n","n_test = 24 # output_lags  (changed)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iyMAi8oaFq8t","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1600100672796,"user_tz":-120,"elapsed":1802,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"120c1baa-46f4-488b-998c-781ab40cb2e0"},"source":["## Split data in train and test set\n","train = emergency_ts_mon[0:-n_test]\n","test = emergency_ts_mon[-n_test:]\n","print(train.shape)\n","print(test.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(8376,)\n","(24,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"E17SmtS0Fq81","colab_type":"code","colab":{}},"source":["## Create lagged values for both input and output window (24)\n","data = train.copy()\n","n_train = len(data)\n","\n","##Create lagged values for input\n","df = pd.DataFrame()\n","for i in range(input_lags,0,-1):\n","    df['t-' + str(i)] = data.shift(i)\n","\n","##Create lagged values for output\n","for j in range(0,output_lags,1):\n","    df['t+' + str(j)] = data.shift(-j)\n","    \n","df = df[input_lags:(n_train-output_lags+1)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w3kdgtGuFq9G","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1600100676044,"user_tz":-120,"elapsed":1354,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"8b116e67-1850-4f0a-b6a6-010f657bafe6"},"source":["## splitting the training set into labels and features\n","X_train = df.iloc[:,:input_lags] # from the beginning to input_lags\n","Y_train = df.iloc[:,input_lags:] # from input_lags to the end\n","\n","## Use the last window of the training set as the features for the test set. This requires a combination of \n","## X_train and Y_train.\n","X_test = X_train.iloc[len(X_train) - 1,:][output_lags:]\n","X_test = X_test.append(Y_train.iloc[len(Y_train) - 1,:]).values.reshape(1,input_lags)\n","Y_test = test[:output_lags].values.reshape(1,output_lags)\n","\n","X_train = X_train.values # 54 steps back (54 lags)\n","Y_train = Y_train.values # 24 steps ahead\n","\n","print(\"X_train: \" + \"type: \" + str(type(X_train)) + \"\\tshape: \" + str(X_train.shape))\n","print(\"Y_train: \" + \"type: \" + str(type(Y_train)) + \"\\tshape: \" + str(Y_train.shape))\n","print(\"X_test: \" + \"type: \" + str(type(X_test)) + \"\\tshape: \" + str(X_test.shape))\n","print(\"Y_test: \" + \"type: \" + str(type(Y_test)) + \"\\tshape: \" + str(Y_test.shape))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["X_train: type: <class 'numpy.ndarray'>\tshape: (8293, 60)\n","Y_train: type: <class 'numpy.ndarray'>\tshape: (8293, 24)\n","X_test: type: <class 'numpy.ndarray'>\tshape: (1, 60)\n","Y_test: type: <class 'numpy.ndarray'>\tshape: (1, 24)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pgGZuED8UOJJ","colab_type":"text"},"source":["$\\textbf{General setup of the algorithm}:$ As far as general parameters go, the booster \"gbtree\" has been used here, ie. I have been using tree based models in each iteration instead of a linear model, which is rarely used. I have started out with a number of estimators of 1,000 and then I have fine tuned the following parameters after try 2: max_depth and min_child_weight (gsearch1), reg_alpha (gsearch2), gamma (gsearch3), subsample and colsample_bytree (gsearch4), reg_lambda (gsearch5).  \n","I have used a feature importance plot of the XGBClassfier model to select the most important features to include. I have included the top 10 features out of the 24 features provided from try 3 onwards.\n","The fine tuned parameters have the following influence on the xg boosting algorithm:  \n","  \n","$\\textit{max_depth:}$ specifies the max depth of a tree and can be used to control overfitting as higher depth will allow the model to learn relations very specific to a particular sample   \n","$\\textit{min_child_weight:}$ this sets the minimum sum of weights of all observations required in a child. Higher values prevent the model from learning too specific relations.  \n","$\\textit{reg_alpha:}$ L1 regularization term. Can be used in case of high dimensionality to make the algorithm run faster. Can be a solution to overfitting in case of a relatively small dataset.  \n","$\\textit{gamma:}$ sets the minimum loss function required to make a split.  \n","$\\textit{subsample:}$ sets the fraction of observations to be random samples of each tree. lower values prevent overfitting but small too small values might lead to underfitting.  \n","$\\textit{colsample_bytree:}$ fraction of columns to be random samples of each tree.  \n","$\\textit{reg_lambda:}$ L2 regularization term. can be a solution to overfitting in case of a relatively small dataset. Can be explored to reduce overfitting."]},{"cell_type":"markdown","metadata":{"id":"wkMGlECaoHJx","colab_type":"text"},"source":["#LightGBM (Gradient Boosting)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"eYzGHCojvx2C","colab_type":"text"},"source":["https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMRegressor.html\n","\n","lightgbm parameters:\n","\n","https://lightgbm.readthedocs.io/en/latest/Parameters.html\n"]},{"cell_type":"markdown","metadata":{"id":"EQL8P44CBMGh","colab_type":"text"},"source":["optimal grid (August 25) :\n","{'estimator__colsample_bytree': 0.8,\n"," 'estimator__learning_rate': 0.1,\n"," 'estimator__max_depth': 8,\n"," 'estimator__min_child_samples': 30,\n"," 'estimator__min_child_weight': 0.01,\n"," 'estimator__n_estimators': 250,\n"," 'estimator__num_leaves': 30,\n"," 'estimator__reg_alpha': 0.0,\n"," 'estimator__reg_lambda': 0.7,\n"," 'estimator__subsample': 1.0}"]},{"cell_type":"markdown","metadata":{"id":"2KXZr7NuUOJe","colab_type":"text"},"source":["## Fitting the optimal model"]},{"cell_type":"code","metadata":{"id":"VOzGeyT2OOYw","colab_type":"code","colab":{}},"source":["# training the best model (24 steps ahead)\n","lgbm_reg_opt_new = LGBMRegressor(random_state=1,learning_rate=0.01, objective = \"root_mean_squared_error\", n_estimators =250, colsample_bytree = 0.8, max_depth = 15, subsample= 1.0, num_leaves=150, min_child_samples=20, min_child_weight =3, reg_lambda = 0.0, reg_alpha= 0.0, eval_metric = \"rmse\",boosting_type=\"gbdt\")\n","\n","lgbm_moreg_fit_new = MultiOutputRegressor(lgbm_reg_opt_new).fit(X_train, Y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nxFQ7WoSmfLm","colab_type":"text"},"source":["## Predictions for monday the 16"]},{"cell_type":"code","metadata":{"id":"ZNKPP8JwOZF3","colab_type":"code","colab":{}},"source":["# 24 steps ahead predictions\n","lgbm_preds_new = lgbm_moreg_fit_new.predict(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ySezbidoPHwh","colab_type":"code","colab":{}},"source":["# MSE\n","mse_lgbm_new = mean_squared_error(Y_test, lgbm_preds_new)\n","sqrt(mse_lgbm_new)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EgHr0iE2nqNq","colab_type":"text"},"source":["## Predictions for tuesday the 17"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"VITrIy65oOsm"},"source":["### Preprocessing for tuesday the 17"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"EfOV39qqoOsn","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600100969288,"user_tz":-120,"elapsed":1329,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"99dc181d-00da-4491-8390-49f8e25e35d8"},"source":["##\n","emergency_ts_tue = emergency_ts.iloc[0:-360 + 24]\n","emergency_ts_tue.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(8424,)"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"po7ZUTwyoOsq","colab":{}},"source":["## Set paramaters\n","input_lags = 60 # 2 and a half times the seasonal period\n","output_lags = 24 # we predict 24 hours ahead\n","n_test = 24 # output_lags  (changed)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"3OQ87ztmoOsu","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1600100971911,"user_tz":-120,"elapsed":1113,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"d2bde903-58e8-4b9a-a371-978af543f7c9"},"source":["## Split data in train and test set\n","train = emergency_ts_tue[0:-n_test]\n","test = emergency_ts_tue[-n_test:]\n","print(train.shape)\n","print(test.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(8400,)\n","(24,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"BDdfkRz2oOsx","colab":{}},"source":["## Create lagged values for both input and output window (24)\n","data = train.copy()\n","n_train = len(data)\n","\n","##Create lagged values for input\n","df = pd.DataFrame()\n","for i in range(input_lags,0,-1):\n","    df['t-' + str(i)] = data.shift(i)\n","\n","##Create lagged values for output\n","for j in range(0,output_lags,1):\n","    df['t+' + str(j)] = data.shift(-j)\n","    \n","df = df[input_lags:(n_train-output_lags+1)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"zE6Rsdv8oOsz","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1600100975573,"user_tz":-120,"elapsed":1359,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"c5fa450d-1f32-4cae-aabc-c37171c50885"},"source":["## splitting the training set into labels and features\n","X_train = df.iloc[:,:input_lags] # from the beginning to input_lags\n","Y_train = df.iloc[:,input_lags:] # from input_lags to the end\n","\n","## Use the last window of the training set as the features for the test set. This requires a combination of \n","## X_train and Y_train.\n","X_test = X_train.iloc[len(X_train) - 1,:][output_lags:]\n","X_test = X_test.append(Y_train.iloc[len(Y_train) - 1,:]).values.reshape(1,input_lags)\n","Y_test = test[:output_lags].values.reshape(1,output_lags)\n","\n","X_train = X_train.values # 54 steps back (54 lags)\n","Y_train = Y_train.values # 24 steps ahead\n","\n","print(\"X_train: \" + \"type: \" + str(type(X_train)) + \"\\tshape: \" + str(X_train.shape))\n","print(\"Y_train: \" + \"type: \" + str(type(Y_train)) + \"\\tshape: \" + str(Y_train.shape))\n","print(\"X_test: \" + \"type: \" + str(type(X_test)) + \"\\tshape: \" + str(X_test.shape))\n","print(\"Y_test: \" + \"type: \" + str(type(Y_test)) + \"\\tshape: \" + str(Y_test.shape))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["X_train: type: <class 'numpy.ndarray'>\tshape: (8317, 60)\n","Y_train: type: <class 'numpy.ndarray'>\tshape: (8317, 24)\n","X_test: type: <class 'numpy.ndarray'>\tshape: (1, 60)\n","Y_test: type: <class 'numpy.ndarray'>\tshape: (1, 24)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"6R0QR-AWout9","colab":{}},"source":["# 24 steps ahead predictions\n","lgbm_preds_new = lgbm_moreg_fit_new.predict(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"xGJVbW8AouuA","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600100979759,"user_tz":-120,"elapsed":1380,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"c5f5b66f-25df-4e8b-8e91-0be6dbec38f0"},"source":["# RMSE\n","mse_lgbm_new = mean_squared_error(Y_test, lgbm_preds_new)\n","sqrt(mse_lgbm_new)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["5.701809247539146"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"av1b_koio8dE"},"source":["## Predictions for wedensday the 18"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"zq_3h79Co8dF"},"source":["### Preprocessing for wedensday the 18"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"cvvNTKe8o8dF","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600100990727,"user_tz":-120,"elapsed":1292,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"a02daba1-e594-4695-a000-a5c4dee866bd"},"source":["##\n","emergency_ts_wed = emergency_ts.iloc[0:-360 + 24*2]\n","emergency_ts_wed.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(8448,)"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"x3hGUsRgo8dH","colab":{}},"source":["## Set paramaters\n","input_lags = 60 # 2 and a half times the seasonal period\n","output_lags = 24 # we predict 24 hours ahead\n","n_test = 24 # output_lags  (changed)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"L8bSTZ97o8dJ","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1600100994244,"user_tz":-120,"elapsed":1994,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"178dde65-f6c5-49b5-bf5c-8fbab31ca967"},"source":["## Split data in train and test set\n","train = emergency_ts_wed[0:-n_test]\n","test = emergency_ts_wed[-n_test:]\n","print(train.shape)\n","print(test.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(8424,)\n","(24,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"zIiBdoQ6o8dM","colab":{}},"source":["## Create lagged values for both input and output window (24)\n","data = train.copy()\n","n_train = len(data)\n","\n","##Create lagged values for input\n","df = pd.DataFrame()\n","for i in range(input_lags,0,-1):\n","    df['t-' + str(i)] = data.shift(i)\n","\n","##Create lagged values for output\n","for j in range(0,output_lags,1):\n","    df['t+' + str(j)] = data.shift(-j)\n","    \n","df = df[input_lags:(n_train-output_lags+1)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"cGsspSNXo8dO","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1600100996671,"user_tz":-120,"elapsed":594,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"0b48ee40-790f-442c-dfb9-fff0d444194e"},"source":["## splitting the training set into labels and features\n","X_train = df.iloc[:,:input_lags] # from the beginning to input_lags\n","Y_train = df.iloc[:,input_lags:] # from input_lags to the end\n","\n","## Use the last window of the training set as the features for the test set. This requires a combination of \n","## X_train and Y_train.\n","X_test = X_train.iloc[len(X_train) - 1,:][output_lags:]\n","X_test = X_test.append(Y_train.iloc[len(Y_train) - 1,:]).values.reshape(1,input_lags)\n","Y_test = test[:output_lags].values.reshape(1,output_lags)\n","\n","X_train = X_train.values # 54 steps back (54 lags)\n","Y_train = Y_train.values # 24 steps ahead\n","\n","print(\"X_train: \" + \"type: \" + str(type(X_train)) + \"\\tshape: \" + str(X_train.shape))\n","print(\"Y_train: \" + \"type: \" + str(type(Y_train)) + \"\\tshape: \" + str(Y_train.shape))\n","print(\"X_test: \" + \"type: \" + str(type(X_test)) + \"\\tshape: \" + str(X_test.shape))\n","print(\"Y_test: \" + \"type: \" + str(type(Y_test)) + \"\\tshape: \" + str(Y_test.shape))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["X_train: type: <class 'numpy.ndarray'>\tshape: (8341, 60)\n","Y_train: type: <class 'numpy.ndarray'>\tshape: (8341, 24)\n","X_test: type: <class 'numpy.ndarray'>\tshape: (1, 60)\n","Y_test: type: <class 'numpy.ndarray'>\tshape: (1, 24)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"qd069tOeo8dT","colab":{}},"source":["# 24 steps ahead predictions\n","lgbm_preds_new = lgbm_moreg_fit_new.predict(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Blv6eh63o8dV","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600101000028,"user_tz":-120,"elapsed":574,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"24f6551d-db00-4fa4-f001-9dcd953a409e"},"source":["# RMSE\n","mse_lgbm_new = mean_squared_error(Y_test, lgbm_preds_new)\n","sqrt(mse_lgbm_new)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["6.289150620708447"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"qNj0_NAQo9T4"},"source":["## Predictions for thursday the 19"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"CknS86D1o9T5"},"source":["### Preprocessing for thursday the 19"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"LYTefH0zo9T6","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600101009057,"user_tz":-120,"elapsed":1221,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"7c6a07ab-b7f3-4d93-ad32-fccdc17d6ff6"},"source":["##\n","emergency_ts_thu = emergency_ts.iloc[0:-360 + 24*3]\n","emergency_ts_thu.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(8472,)"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Ek6JusX4o9T9","colab":{}},"source":["## Set paramaters\n","input_lags = 60 # 2 and a half times the seasonal period\n","output_lags = 24 # we predict 24 hours ahead\n","n_test = 24 # output_lags  (changed)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"g4JC2GMUo9UA","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1600101012404,"user_tz":-120,"elapsed":883,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"2cbb19ca-1b32-40fb-c870-6173ded5de74"},"source":["## Split data in train and test set\n","train = emergency_ts_thu[0:-n_test]\n","test = emergency_ts_thu[-n_test:]\n","print(train.shape)\n","print(test.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(8448,)\n","(24,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Z0WM4LKto9UD","colab":{}},"source":["## Create lagged values for both input and output window (24)\n","data = train.copy()\n","n_train = len(data)\n","\n","##Create lagged values for input\n","df = pd.DataFrame()\n","for i in range(input_lags,0,-1):\n","    df['t-' + str(i)] = data.shift(i)\n","\n","##Create lagged values for output\n","for j in range(0,output_lags,1):\n","    df['t+' + str(j)] = data.shift(-j)\n","    \n","df = df[input_lags:(n_train-output_lags+1)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"QXNjFULRo9UI","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1600101016309,"user_tz":-120,"elapsed":1579,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"4a2c9a9c-28be-4c9e-929e-8da0aeab5f7a"},"source":["## splitting the training set into labels and features\n","X_train = df.iloc[:,:input_lags] # from the beginning to input_lags\n","Y_train = df.iloc[:,input_lags:] # from input_lags to the end\n","\n","## Use the last window of the training set as the features for the test set. This requires a combination of \n","## X_train and Y_train.\n","X_test = X_train.iloc[len(X_train) - 1,:][output_lags:]\n","X_test = X_test.append(Y_train.iloc[len(Y_train) - 1,:]).values.reshape(1,input_lags)\n","Y_test = test[:output_lags].values.reshape(1,output_lags)\n","\n","X_train = X_train.values # 54 steps back (54 lags)\n","Y_train = Y_train.values # 24 steps ahead\n","\n","print(\"X_train: \" + \"type: \" + str(type(X_train)) + \"\\tshape: \" + str(X_train.shape))\n","print(\"Y_train: \" + \"type: \" + str(type(Y_train)) + \"\\tshape: \" + str(Y_train.shape))\n","print(\"X_test: \" + \"type: \" + str(type(X_test)) + \"\\tshape: \" + str(X_test.shape))\n","print(\"Y_test: \" + \"type: \" + str(type(Y_test)) + \"\\tshape: \" + str(Y_test.shape))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["X_train: type: <class 'numpy.ndarray'>\tshape: (8365, 60)\n","Y_train: type: <class 'numpy.ndarray'>\tshape: (8365, 24)\n","X_test: type: <class 'numpy.ndarray'>\tshape: (1, 60)\n","Y_test: type: <class 'numpy.ndarray'>\tshape: (1, 24)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"lhxkSUspo9UO","colab":{}},"source":["# 24 steps ahead predictions\n","lgbm_preds_new = lgbm_moreg_fit_new.predict(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"vsQBVPB8o9UQ","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600101019542,"user_tz":-120,"elapsed":1264,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"5ed07fcc-639a-4842-ecb1-5cafb4332084"},"source":["# RMSE\n","mse_lgbm_new = mean_squared_error(Y_test, lgbm_preds_new)\n","sqrt(mse_lgbm_new)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["5.430993191142919"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"YjZG7sAvo-yo"},"source":["## Predictions for friday the 20"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"hlB9D-CNo-yp"},"source":["### Preprocessing for friday the 20"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"gREIYr--o-ys","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600101084042,"user_tz":-120,"elapsed":1260,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"11cf8292-c888-42fc-b109-3d0ebcf55277"},"source":["##\n","emergency_ts_fri = emergency_ts.iloc[0:-360 + 24*4]\n","emergency_ts_fri.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(8496,)"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"klpSThePo-yw","colab":{}},"source":["## Set paramaters\n","input_lags = 60 # 2 and a half times the seasonal period\n","output_lags = 24 # we predict 24 hours ahead\n","n_test = 24 # output_lags  (changed)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"zbkYXXoFo-yz","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1600101087154,"user_tz":-120,"elapsed":1410,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"dbce724b-f4c2-4854-a9ae-9386f604f535"},"source":["## Split data in train and test set\n","train = emergency_ts_fri[0:-n_test]\n","test = emergency_ts_fri[-n_test:]\n","print(train.shape)\n","print(test.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(8472,)\n","(24,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"f_NhjIUgo-y2","colab":{}},"source":["## Create lagged values for both input and output window (24)\n","data = train.copy()\n","n_train = len(data)\n","\n","##Create lagged values for input\n","df = pd.DataFrame()\n","for i in range(input_lags,0,-1):\n","    df['t-' + str(i)] = data.shift(i)\n","\n","##Create lagged values for output\n","for j in range(0,output_lags,1):\n","    df['t+' + str(j)] = data.shift(-j)\n","    \n","df = df[input_lags:(n_train-output_lags+1)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"KWbNfVfeo-y4","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1600101090729,"user_tz":-120,"elapsed":1565,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"907874f5-c20e-48b1-9fd8-9b8656929bf4"},"source":["## splitting the training set into labels and features\n","X_train = df.iloc[:,:input_lags] # from the beginning to input_lags\n","Y_train = df.iloc[:,input_lags:] # from input_lags to the end\n","\n","## Use the last window of the training set as the features for the test set. This requires a combination of \n","## X_train and Y_train.\n","X_test = X_train.iloc[len(X_train) - 1,:][output_lags:]\n","X_test = X_test.append(Y_train.iloc[len(Y_train) - 1,:]).values.reshape(1,input_lags)\n","Y_test = test[:output_lags].values.reshape(1,output_lags)\n","\n","X_train = X_train.values # 54 steps back (54 lags)\n","Y_train = Y_train.values # 24 steps ahead\n","\n","print(\"X_train: \" + \"type: \" + str(type(X_train)) + \"\\tshape: \" + str(X_train.shape))\n","print(\"Y_train: \" + \"type: \" + str(type(Y_train)) + \"\\tshape: \" + str(Y_train.shape))\n","print(\"X_test: \" + \"type: \" + str(type(X_test)) + \"\\tshape: \" + str(X_test.shape))\n","print(\"Y_test: \" + \"type: \" + str(type(Y_test)) + \"\\tshape: \" + str(Y_test.shape))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["X_train: type: <class 'numpy.ndarray'>\tshape: (8389, 60)\n","Y_train: type: <class 'numpy.ndarray'>\tshape: (8389, 24)\n","X_test: type: <class 'numpy.ndarray'>\tshape: (1, 60)\n","Y_test: type: <class 'numpy.ndarray'>\tshape: (1, 24)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"aQHi6Py5o-y7","colab":{}},"source":["# 24 steps ahead predictions\n","lgbm_preds_new = lgbm_moreg_fit_new.predict(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"9T2Xq6JLo-y9","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600101093394,"user_tz":-120,"elapsed":1411,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"28af9029-8caf-4773-c062-c634da6bbda6"},"source":["# RMSE\n","mse_lgbm_new = mean_squared_error(Y_test, lgbm_preds_new)\n","sqrt(mse_lgbm_new)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["5.645653897366603"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"QHxvGWHVo_bi"},"source":["## Predictions for saturday the 21"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"QyoHr-X0o_bk"},"source":["### Preprocessing for saturday the 21"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"dn9KOyafo_bm","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600101106444,"user_tz":-120,"elapsed":1279,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"a29f56f3-5602-4525-d002-ec5fe083f06f"},"source":["##\n","emergency_ts_sat = emergency_ts.iloc[0:-360 + 24*5]\n","emergency_ts_sat.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(8520,)"]},"metadata":{"tags":[]},"execution_count":41}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"wWYmn7nyo_bq","colab":{}},"source":["## Set paramaters\n","input_lags = 60 # 2 and a half times the seasonal period\n","output_lags = 24 # we predict 24 hours ahead\n","n_test = 24 # output_lags  (changed)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"x3zU1VbRo_bs","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1600101107284,"user_tz":-120,"elapsed":533,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"1018ed89-a4c6-4551-c751-0edccf7aa8c7"},"source":["## Split data in train and test set\n","train = emergency_ts_sat[0:-n_test]\n","test = emergency_ts_sat[-n_test:]\n","print(train.shape)\n","print(test.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(8496,)\n","(24,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"xslKYI6Co_bt","colab":{}},"source":["## Create lagged values for both input and output window (24)\n","data = train.copy()\n","n_train = len(data)\n","\n","##Create lagged values for input\n","df = pd.DataFrame()\n","for i in range(input_lags,0,-1):\n","    df['t-' + str(i)] = data.shift(i)\n","\n","##Create lagged values for output\n","for j in range(0,output_lags,1):\n","    df['t+' + str(j)] = data.shift(-j)\n","    \n","df = df[input_lags:(n_train-output_lags+1)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"VnVB8W3bo_bv","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1600101113015,"user_tz":-120,"elapsed":1263,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"21f29961-0a12-46fb-a95e-8bb3a6074252"},"source":["## splitting the training set into labels and features\n","X_train = df.iloc[:,:input_lags] # from the beginning to input_lags\n","Y_train = df.iloc[:,input_lags:] # from input_lags to the end\n","\n","## Use the last window of the training set as the features for the test set. This requires a combination of \n","## X_train and Y_train.\n","X_test = X_train.iloc[len(X_train) - 1,:][output_lags:]\n","X_test = X_test.append(Y_train.iloc[len(Y_train) - 1,:]).values.reshape(1,input_lags)\n","Y_test = test[:output_lags].values.reshape(1,output_lags)\n","\n","X_train = X_train.values # 54 steps back (54 lags)\n","Y_train = Y_train.values # 24 steps ahead\n","\n","print(\"X_train: \" + \"type: \" + str(type(X_train)) + \"\\tshape: \" + str(X_train.shape))\n","print(\"Y_train: \" + \"type: \" + str(type(Y_train)) + \"\\tshape: \" + str(Y_train.shape))\n","print(\"X_test: \" + \"type: \" + str(type(X_test)) + \"\\tshape: \" + str(X_test.shape))\n","print(\"Y_test: \" + \"type: \" + str(type(Y_test)) + \"\\tshape: \" + str(Y_test.shape))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["X_train: type: <class 'numpy.ndarray'>\tshape: (8413, 60)\n","Y_train: type: <class 'numpy.ndarray'>\tshape: (8413, 24)\n","X_test: type: <class 'numpy.ndarray'>\tshape: (1, 60)\n","Y_test: type: <class 'numpy.ndarray'>\tshape: (1, 24)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"owy46o4Yo_by","colab":{}},"source":["# 24 steps ahead predictions\n","lgbm_preds_new = lgbm_moreg_fit_new.predict(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Rmty5DVzo_b0","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600101115887,"user_tz":-120,"elapsed":1106,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"dd154eeb-8d58-45f3-e3d6-1aa5159a8526"},"source":["# RMSE\n","mse_lgbm_new = mean_squared_error(Y_test, lgbm_preds_new)\n","sqrt(mse_lgbm_new)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["6.660966467734799"]},"metadata":{"tags":[]},"execution_count":47}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"x7v3jU4VpADx"},"source":["## Predictions for sunday the 22"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"1R1_RWFApAD1"},"source":["### Preprocessing for sunday the 22"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"gPhz82w9pAD1","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600101164105,"user_tz":-120,"elapsed":1785,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"8a5130da-8c7b-48ad-a099-f628f3551ccc"},"source":["##\n","emergency_ts_sun = emergency_ts.iloc[0:-360 + 24*6]\n","emergency_ts_sun.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(8544,)"]},"metadata":{"tags":[]},"execution_count":48}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"4-vI2fV_pAD7","colab":{}},"source":["## Set paramaters\n","input_lags = 60 # 2 and a half times the seasonal period\n","output_lags = 24 # we predict 24 hours ahead\n","n_test = 24 # output_lags  (changed)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"GJ41wSB_pAEB","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1600101165977,"user_tz":-120,"elapsed":1570,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"62562310-9d1d-48f2-9d87-331ddb55de14"},"source":["## Split data in train and test set\n","train = emergency_ts_sun[0:-n_test]\n","test = emergency_ts_sun[-n_test:]\n","print(train.shape)\n","print(test.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(8520,)\n","(24,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"35rlXlb9pAEG","colab":{}},"source":["## Create lagged values for both input and output window (24)\n","data = train.copy()\n","n_train = len(data)\n","\n","##Create lagged values for input\n","df = pd.DataFrame()\n","for i in range(input_lags,0,-1):\n","    df['t-' + str(i)] = data.shift(i)\n","\n","##Create lagged values for output\n","for j in range(0,output_lags,1):\n","    df['t+' + str(j)] = data.shift(-j)\n","    \n","df = df[input_lags:(n_train-output_lags+1)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"V6KlZr_vpAEN","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1600101171706,"user_tz":-120,"elapsed":1967,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"114c899b-9646-49f1-ff92-dad83469f864"},"source":["## splitting the training set into labels and features\n","X_train = df.iloc[:,:input_lags] # from the beginning to input_lags\n","Y_train = df.iloc[:,input_lags:] # from input_lags to the end\n","\n","## Use the last window of the training set as the features for the test set. This requires a combination of \n","## X_train and Y_train.\n","X_test = X_train.iloc[len(X_train) - 1,:][output_lags:]\n","X_test = X_test.append(Y_train.iloc[len(Y_train) - 1,:]).values.reshape(1,input_lags)\n","Y_test = test[:output_lags].values.reshape(1,output_lags)\n","\n","X_train = X_train.values # 54 steps back (54 lags)\n","Y_train = Y_train.values # 24 steps ahead\n","\n","print(\"X_train: \" + \"type: \" + str(type(X_train)) + \"\\tshape: \" + str(X_train.shape))\n","print(\"Y_train: \" + \"type: \" + str(type(Y_train)) + \"\\tshape: \" + str(Y_train.shape))\n","print(\"X_test: \" + \"type: \" + str(type(X_test)) + \"\\tshape: \" + str(X_test.shape))\n","print(\"Y_test: \" + \"type: \" + str(type(Y_test)) + \"\\tshape: \" + str(Y_test.shape))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["X_train: type: <class 'numpy.ndarray'>\tshape: (8437, 60)\n","Y_train: type: <class 'numpy.ndarray'>\tshape: (8437, 24)\n","X_test: type: <class 'numpy.ndarray'>\tshape: (1, 60)\n","Y_test: type: <class 'numpy.ndarray'>\tshape: (1, 24)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Hqr53yu3pAEU","colab":{}},"source":["# 24 steps ahead predictions\n","lgbm_preds_new = lgbm_moreg_fit_new.predict(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"EV7vvRrBpAEZ","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600101175120,"user_tz":-120,"elapsed":1033,"user":{"displayName":"Manuel S","photoUrl":"","userId":"12634565971130299273"}},"outputId":"27249cf0-9549-4648-d739-b904f6aee913"},"source":["# RMSE\n","mse_lgbm_new = mean_squared_error(Y_test, lgbm_preds_new)\n","sqrt(mse_lgbm_new)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["4.489210961067223"]},"metadata":{"tags":[]},"execution_count":54}]},{"cell_type":"code","metadata":{"id":"lHk1gdz5qbjU","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}